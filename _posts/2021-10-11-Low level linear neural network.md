---
layout: post
title:  "[TensorFlow] 미니배치 경사하강법을 이용한 저수준 선형 신경망 구현"
---



#[딥러닝 2차 과제] 2014210150 박성호

## 목표
### 1.  미니 배치 경사하강법을 적용하여 모델 훈련(batch_size = 100)
### 2. `metrics`로 예측 정확도를 훈련 과정 중에 측정하는 기능 추가
### 3. 세 개의 층을 사용하는 모델을 구현

## 저수준 선형 분류 신경망 구현

**기본 설정**
1. 그래픽 카드 사용을 위한 지정

2. 공통 모듈 임포트 및  데이터셋 생성




```python
!nvidia-smi
```

    NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.


​    


```python
# 텐서플로우와 넘파이 사용을 위한 임포트
import tensorflow as tf
import numpy as np

from tensorflow import keras

#그래프를 그리기 위한 모듈 임포트
import matplotlib.pyplot as plt

# 텐서플로우 버전 확인
print(tf.__version__)

# GPU 사용 여부 확인
print(tf.config.list_physical_devices('GPU'))
```

    2.6.0
    []


### 데이터셋 생성

>- `np.random.multivariate_normal()`
    - 다변량 정규분포를 따르는 데이터 생성
    - 평균값과 공분산 지정 필요
- 음성 데이터셋
    - 샘플 수: 1,000
    - 평균값: `[0, 3]`
    - 공분산: `[[1, 0.5],[0.5, 1]]`
- 양성 데이터셋
    - 샘플 수: 1,000
    - 평균값: `[3, 0]`
    - 공분산: `[[1, 0.5],[0.5, 1]]`


1000개 샘플의 양성 과 음성 데이터셋 두 가지를 준비합니다.


```python
num_samples_per_class = 1000

# 음성 데이터셋
negative_samples = np.random.multivariate_normal(
    mean=[0, 3], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)

# 양성 데이터셋
positive_samples = np.random.multivariate_normal(
    mean=[3, 0], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)
```

두 개의 `(1000, 2)` 모양의 양성, 음성 데이터셋을 하나의 `(2000, 2)` 모양의 데이터셋으로 합칩니다.

자료형을 `np.float32`로 지정(`default = np.float64`)

**자료형을 지정하는 이유**

넘파이 어레이 생성 시 기본 자료형인 `np.float64`를 사용하게 되는데, 현재 사용하는 데이터셋의 크기는 그리 크지않기 때문에 메모리 크기가 더 작은 `np.float32`로 지정하여 사용합니다.

따라서 메모리를 효율적으로 관리하여 실행시간을 줄이고, 메모리 크기를 최소화 하여 관리할 수 있게됩니다.


```python
inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)
```

`np.zeros()`와 `np.ones()`메서드를 통해 음성 샘플의 타깃은 0, 양성 샘플의 타깃은 1로 지정합니다.


```python
targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype="float32"),
                     np.ones((num_samples_per_class, 1), dtype="float32")))
print(targets)
```

    [[0.]
     [0.]
     [0.]
     ...
     [1.]
     [1.]
     [1.]]


양성, 음성 샘플을 색깔로 구분하면 다음과 같습니다.

- `inputs[:, 0]`: x 좌표
- `inputs[:, 1]`: x 좌표
- `c=targets[:, 0]`: 0 또는 1에 따른 색상 지정


```python
plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])
plt.show()
```



![output_13_0](https://user-images.githubusercontent.com/80394894/136712662-a06b080e-8663-44f3-b1a3-100d8627cc23.png)



이제 데이터셋 생성을 완료 했습니다.

이를 가지고 훈련을 위한 데이터 전처리 작업을 수행합니다.

### 3층(3-Layer) 가중치 변수 텐서 생성 및 초기화
세 개의 층을 사용하는 모델을 구현하기 위해 각 층의 가중치 변수 텐서를 생성합니다.

먼저, 각 층(Layer)마다 연결하기 특성을 선언합니다.


```python
inter_layers_dim1 = 3 # 1층 출력 샘플의 특성 수
inter_layers_dim2 = 2 # 2층 출력 샘플의 특성 수
```

이후, 각 층마다 가중치 및 편향을 초기화 하기 위한 연산을 수행합니다.

가중치와 편향은 tensorflow의 `tf.Variable()` 메서드를 통해 초기화합니다.

- 가중치 :  `tf.random.uniform()` 메서드를 통해 무작위로 설정

- 편향 : `tf.zeros()` 메서드를 통해 0으로 설정

**1층(Layer) 가중치 및 편향 초기화**

- 입력 샘플의 특성은 (양성, 음성)으로 2개의 입력을 받았으며
초기화를 함으로써 출력의 특성을 증가시키거나 감소시킬 수 있습니다.

1층 레이어에서는 2개의 특성을 입력받아 3개의 특성으로 초기화하여 출력합니다.


```python
input_dim1 = 2                     # 입력 샘플의 특성수
output_dim1 = inter_layers_dim1    # 출력 샘플의 특성수

# 가중치: 무작위 초기화
W1 = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim1, output_dim1)))

# 편향: 0으로 초기화
b1 = tf.Variable(initial_value=tf.zeros(shape=(output_dim1,)))
```

**2층(Layer) 가중치 및 편향 초기화**

1층의 출력 값인 3개의 특성을 입력 값으로 받아 다시 2개의 특성으로 초기화 하여 출력합니다.


```python
input_dim2 = inter_layers_dim1           # 입력 샘플의 특성수(첫 번째 layer의 출력 결과)
output_dim2 = inter_layers_dim2          # 출력 샘플의 특성수

# 가중치: 무작위 초기화
W2 = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim2, output_dim2)))

# 편향: 0으로 초기화
b2 = tf.Variable(initial_value=tf.zeros(shape=(output_dim2,)))
```

**3층(Layer) 가중치 및 편향 초기화**

2층의 출력 값인 2개의 특성을 입력 값으로 받아 최종적으로 1개의 특성을 초기화 하도록 설정합니다.


```python
input_dim3 = inter_layers_dim2           # 입력 샘플의 특성수(두 번째 layer의 출력 결과)
output_dim3 = 1                    # 하나의 값으로 출력(양성 음성을 예측하기 위함)

# 가중치: 무작위 초기화
W3 = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim3, output_dim3)))

# 편향: 0으로 초기화
b3 = tf.Variable(initial_value=tf.zeros(shape=(output_dim3,)))
```

### 예측 모델(함수) 선언
- 각 층을 사용하는 모델의 출력값을 계산하는 과정으로 함수를 선언합니다.

- 각 함수에서는 층마다 입력 데이터에서 가중치를 곱한 후 편향을 더하는 연산을 수행하여 출력하도록 합니다.

**1층 예측 모델 함수**


```python
def layer1(inputs, activation=None):
    outputs = tf.matmul(inputs, W1) + b1
    if activation != None:
        return activation(outputs)
    else:
        return outputs
```

**2층 예측 모델 함수**


```python
def layer2(inputs, activation=None):
    outputs = tf.matmul(inputs, W2) + b2
    if activation != None:
        return activation(outputs)
    else:
        return outputs
```

**3층 예측 모델 함수**


```python
def layer3(inputs, activation=None):
    outputs = tf.matmul(inputs, W3) + b3
    if activation != None:
        return activation(outputs)
    else:
        return outputs
```

**각 층을 연결하여 연산하는 model 함수 생성**

model() 함수는 각 층마다 순서대로 선언된 예측 모델 함수 연산을 수행하여 1개의 최종적인 출력 값을 얻을 수 있도록 연결해주는 함수입니다.


```python
def model(inputs):
    layer1_outputs = layer1(inputs, tf.nn.relu)
    layer2_outputs = layer2(layer1_outputs)
    layer3_outputs = layer3(layer2_outputs)
    return layer3_outputs
```

### 손실 함수 : 평균 제곱 오차(MSE)
- `tf.reduce_mean()`메서드를 통해 텐서에 포함된 항목들의 평균값 계산합니다.

- `tf.reduce_mean()`메서드는 넘파이의 `np.mean()`과 결과는 동일하며, 텐서플로우의 텐서를 대상으로 사용합니다.


```python
def square_loss(targets, predictions):
    per_sample_losses = tf.square(targets - predictions)
    return tf.reduce_mean(per_sample_losses)
```

### 훈련 단계

이제 모델을 훈련하기 위한 함수를 생성하여 모델훈련을 진행합니다.

- 먼저 `tf.GradientTape()`메서드를 통해 하나의 배치에 대하여 예측값을 계산하고,

- 이후 손실 함수의 그레이디언트를 이용하여 가중치와 편향을 업데이트 하는 함수를 생성합니다.


```python
learning_rate = 0.1

def training_step(inputs, targets):
    with tf.GradientTape() as tape:
        predictions = model(inputs)
        loss = square_loss(targets, predictions)
    grad_loss_wrt_W1, grad_loss_wrt_b1, grad_loss_wrt_W2, grad_loss_wrt_b2, grad_loss_wrt_W3, grad_loss_wrt_b3 = tape.gradient(loss, [W1, b1, W2, b2, W3, b3])
    W1.assign_sub(grad_loss_wrt_W1 * learning_rate)
    b1.assign_sub(grad_loss_wrt_b1 * learning_rate)
    W2.assign_sub(grad_loss_wrt_W2 * learning_rate)
    b2.assign_sub(grad_loss_wrt_b2 * learning_rate)
    W3.assign_sub(grad_loss_wrt_W3 * learning_rate)
    b3.assign_sub(grad_loss_wrt_b3 * learning_rate)

    return loss
```

### 예측 정확도 측정을 위한 metric() 함수 만들기

훈련 도중 예측 정확도를 측정하기 위해 예측 정확도를 출력해주는 함수를 생성합니다.
- 훈련 데이터를 `model()`함수를 통해 예측 모델 함수 연산을 수행합니다.
- 예측된 값을 `np.where()`메서드를 통해 조건문에 따른 값을 설정합니다. (예측 값 > 0.5 이면 1, 아니면 0)
- `np.equals()`메서드를 통해 예측된 값이 타깃과 일치하는지 판단합니다.
- `np.mean()`메서드를 통해 일치한 값들의 평균을 내어 정확도를 반환합니다.


```python
def metric(inputs, targets):
    predictions = model(inputs)
    predictions = np.where(predictions > 0.5, 1.0, 0)
    metric_result = np.mean(np.equal(predictions, targets))

    return metric_result
```

### 미니 배치 훈련을 위한 테스트 과정

미니 배치 훈련을 하기 위한 조건문을 테스트하는 과정입니다.

배치 사이즈를 설정하고, for문을 통해 배치 사이즈(100) 만큼 나누어 배열을 출력하는 지 확인합니다.

총 100개씩 20묶음으로 배열을 반환하면 성공입니다.




```python
batch_size = 100

# inputs 미니 배치 나누기
for first in range(0, len(inputs), batch_size):
    mini_batch_inputs = inputs[first:first+batch_size]
    print(mini_batch_inputs)

# targets 미니 배치 나누기
for first in range(0, len(targets), batch_size):
    mini_batch_targets = targets[first:first+batch_size]
    print(mini_batch_targets)
```

    [[-0.40376148  1.3666333 ]
     [ 0.759227    3.006888  ]
     [-1.0911758   1.7305837 ]
     [ 0.743376    2.678977  ]
     [-0.8499121   3.2999685 ]
     [-2.654612    2.6105247 ]
     [-0.33211473  2.8697972 ]
     [-0.35805503  2.3003454 ]
     [-0.01450323  2.037338  ]
     [ 0.99264216  3.048256  ]
     [ 1.3060539   3.3673098 ]
     [-0.07856762  2.878165  ]
     [-1.3001462   1.2461264 ]
     [ 0.07794467  3.3000538 ]
     [ 0.55943704  2.5341387 ]
     [-1.8585327   2.1690674 ]
     [-1.2986528   1.627812  ]
     [ 0.4988232   3.723962  ]
     [-0.13331944  3.67568   ]
     [-0.61999613  2.6283207 ]
     [-1.9280431   2.6598938 ]
     [ 0.1150467   1.6437806 ]
     [-1.2504843   2.9759765 ]
     [-0.16793077  4.095244  ]
     [ 1.5568726   4.5027804 ]
     [-0.9813349   1.7265234 ]
     [ 1.4726554   3.5888069 ]
     [-0.66860884  3.315111  ]
     [-0.43143612  2.5023437 ]
     [ 0.6286274   3.3826413 ]
     [ 0.15114826  2.1551957 ]
     [ 3.3788142   4.885067  ]
     [ 0.2560175   2.8434703 ]
     [ 1.429948    5.303004  ]
     [-0.08219329  2.7563086 ]
     [ 0.10945817  2.6310925 ]
     [ 1.8546283   4.1725435 ]
     [ 0.85757905  3.5303712 ]
     [ 0.14698084  3.1858335 ]
     [-0.8535101   1.185816  ]
     [ 0.30995408  2.9236348 ]
     [-1.0708574   3.2828481 ]
     [-0.5724563   2.0072346 ]
     [ 1.1769782   3.3217654 ]
     [ 0.52845764  2.6611714 ]
     [-1.7873362   0.901614  ]
     [ 1.1629264   4.295557  ]
     [ 0.6134454   2.4498796 ]
     [-1.7862886   3.8064013 ]
     [ 1.387134    4.4764886 ]
     [ 0.02830021  2.808362  ]
     [ 0.5780995   3.8686397 ]
     [-0.361558    3.2761605 ]
     [ 0.44479567  3.9090064 ]
     [-1.5002987   4.431716  ]
     [-0.56641746  3.8511937 ]
     [ 1.7041758   3.9969704 ]
     [ 0.8812449   3.0801647 ]
     [-0.31366128  3.735315  ]
     [-0.23023318  4.173593  ]
     [ 1.0590457   3.9485753 ]
     [ 0.93584996  3.6224513 ]
     [-1.2497355   2.652274  ]
     [ 1.7399007   3.6643357 ]
     [-1.0399375   2.264608  ]
     [-0.73764455  3.2653165 ]
     [ 0.47965965  3.4466221 ]
     [ 0.15785253  1.6465672 ]
     [ 1.188529    3.6055927 ]
     [ 0.3242152   4.856946  ]
     [-0.8621336   1.4263283 ]
     [-0.6111298   2.1987927 ]
     [-0.46467125  3.9272459 ]
     [-0.7344531   3.1836665 ]
     [ 0.2936638   2.7873626 ]
     [ 1.0410178   3.841995  ]
     [ 0.23980221  2.2241445 ]
     [ 0.15725526  5.291856  ]
     [ 1.1915016   3.9720929 ]
     [-1.2924242   2.065391  ]
     [ 0.8903412   4.2014904 ]
     [ 0.37212852  3.188201  ]
     [ 0.66067237  3.5647607 ]
     [-0.16979805  3.0469053 ]
     [ 1.6788982   2.796809  ]
     [ 0.5252191   1.9473692 ]
     [ 0.08600422  4.007601  ]
     [-0.46949327  2.2853706 ]
     [ 0.8069448   4.0485573 ]
     [-1.8001808   2.4897277 ]
     [ 0.48051858  1.7998936 ]
     [-0.0177382   4.6747637 ]
     [-0.68671066  2.353116  ]
     [-1.8215814   2.8187857 ]
     [-0.6523716   1.5064164 ]
     [-0.10531558  3.4219222 ]
     [-0.78571296  2.2199829 ]
     [-1.1681933   4.2140555 ]
     [-0.9366949   2.2957458 ]
     [-1.2637032   2.2526968 ]]
    [[-0.23006068  2.5968537 ]
     [ 0.45793393  2.4207773 ]
     [-0.17175822  3.4257147 ]
     [ 1.2392467   3.7501004 ]
     [-0.9591246   1.5512742 ]
     [ 0.63768053  3.0060787 ]
     [ 1.0713233   3.4172204 ]
     [-0.68923634  2.8008919 ]
     [-1.4932141   1.3578355 ]
     [-0.43522972  3.2031596 ]
     [-0.57997143  4.2591295 ]
     [ 0.0400399   3.573169  ]
     [-0.36401772  0.57185376]
     [ 1.2829071   5.036559  ]
     [ 0.55793834  2.81527   ]
     [-0.06235971  3.1701286 ]
     [-0.01515318  4.195653  ]
     [ 0.07512446  2.6135294 ]
     [ 1.1323745   2.9313025 ]
     [ 1.4171106   4.316046  ]
     [ 0.22196333  3.7840724 ]
     [ 0.11779279  2.6355538 ]
     [-0.30260092  3.4990737 ]
     [ 0.3146557   3.057549  ]
     [ 1.9683491   4.4567423 ]
     [ 0.7238435   2.9291716 ]
     [ 0.55336666  2.5116813 ]
     [-0.74129117  3.049821  ]
     [-0.40153196  0.516527  ]
     [ 1.752107    2.814646  ]
     [-0.7849748   2.5949745 ]
     [-0.20811115  3.881695  ]
     [ 1.1280009   5.205806  ]
     [ 0.32090488  3.9207268 ]
     [-0.65225416  2.3849056 ]
     [ 1.8399644   4.06426   ]
     [ 0.449248    4.0754576 ]
     [ 0.12875251  2.5760515 ]
     [ 0.2856522   3.8331501 ]
     [-0.01661703  3.0448895 ]
     [ 0.74327976  3.518859  ]
     [ 0.8785202   3.6647778 ]
     [-1.0089074   1.2474972 ]
     [-0.6897624   3.6534753 ]
     [ 0.13676259  2.5100951 ]
     [ 0.03021484  4.324607  ]
     [-0.03323762  2.133142  ]
     [-0.34528825  4.785495  ]
     [ 1.0458628   3.4567533 ]
     [-1.4782771   3.3005981 ]
     [ 0.9379673   4.421275  ]
     [-1.7271518   1.5786626 ]
     [ 2.3111289   4.986025  ]
     [ 1.3100976   2.3572247 ]
     [ 1.218227    5.1844635 ]
     [ 0.7577221   3.2738335 ]
     [ 1.4958717   4.138578  ]
     [-0.75174737  2.6649325 ]
     [ 0.4865867   3.3343866 ]
     [-0.66124654  1.8742121 ]
     [ 0.9595461   5.711318  ]
     [-1.5803306   1.8473097 ]
     [-0.69186175  3.5768883 ]
     [ 1.0721296   3.6313128 ]
     [-1.4705871   1.5532166 ]
     [ 0.730104    4.4108386 ]
     [ 0.7174375   3.6616862 ]
     [ 0.94336677  3.2011695 ]
     [-0.04066451  1.3786258 ]
     [ 1.3253827   4.0287056 ]
     [-0.21820022  2.7040787 ]
     [-0.04129035  0.8743612 ]
     [-0.92698467  1.2603425 ]
     [ 0.6326009   2.8480883 ]
     [ 0.15499863  2.865407  ]
     [ 1.7998056   2.344552  ]
     [-0.52904624  3.862859  ]
     [-1.6645402   2.7617157 ]
     [-0.6995833   3.180399  ]
     [-1.1108623   3.502572  ]
     [-0.46275768  2.7308624 ]
     [ 0.01318465  2.4435894 ]
     [-0.886623    2.3805356 ]
     [ 0.52179253  4.249498  ]
     [-0.46222264  2.8289337 ]
     [ 0.7708321   6.0747533 ]
     [ 0.1282656   3.3240438 ]
     [-1.438318    2.6060724 ]
     [ 1.6227641   3.4676082 ]
     [ 0.6370962   4.0820155 ]
     [ 0.6619857   3.5156775 ]
     [-0.35409784  2.8042338 ]
     [ 1.1573704   4.6496844 ]
     [-0.0082882   2.443494  ]
     [-1.2354444   3.363377  ]
     [-1.1750815   2.268854  ]
     [ 0.6001812   2.3599877 ]
     [ 0.9004974   2.476199  ]
     [-1.5767566   2.0596733 ]
     [-1.3115829   1.6053698 ]]
    [[-1.63229570e-01  2.88781404e+00]
     [-2.21766800e-01  3.58974433e+00]
     [-1.09118866e-02  3.37398863e+00]
     [-4.30479616e-01  1.92704701e+00]
     [ 8.23896900e-02  2.86524487e+00]
     [-1.18893957e+00  2.85093880e+00]
     [-1.59887567e-01  4.48641491e+00]
     [ 1.83891249e+00  2.81877828e+00]
     [ 7.88309872e-01  2.58891320e+00]
     [-6.20254636e-01  2.92724156e+00]
     [-7.87541687e-01  2.37286329e+00]
     [-3.27264130e-01  2.48928714e+00]
     [ 1.14631113e-02  3.34864783e+00]
     [ 8.40450585e-01  2.67774558e+00]
     [-7.94649839e-01  2.13564348e+00]
     [ 4.78351638e-02  3.18732429e+00]
     [-1.85838377e+00  2.16091323e+00]
     [-8.76912653e-01  2.43770623e+00]
     [ 1.88797995e-01  3.26938462e+00]
     [ 3.37588880e-03  2.90844250e+00]
     [-5.24377525e-01  1.10734355e+00]
     [ 2.41106176e+00  4.77918053e+00]
     [-6.79559946e-01  1.72362781e+00]
     [-1.11059535e+00  1.49233305e+00]
     [-1.92471600e+00  3.18010855e+00]
     [-1.95471585e+00  1.59762084e+00]
     [ 1.58969060e-01  1.38185728e+00]
     [-1.26459467e+00  1.30599141e+00]
     [-2.47771442e-01  3.92894030e+00]
     [-1.43783140e+00  1.91607678e+00]
     [-1.11777854e+00  3.62477469e+00]
     [-1.14675760e+00  2.60769224e+00]
     [ 6.26881182e-01  2.81429124e+00]
     [-5.44301391e-01  3.81510615e+00]
     [ 1.09269805e-01  2.24933410e+00]
     [ 2.25543094e+00  4.64004135e+00]
     [-6.53448164e-01  2.48559189e+00]
     [ 2.08237696e+00  1.83121443e+00]
     [-6.72332644e-01  2.57581806e+00]
     [ 1.59003699e+00  4.74538326e+00]
     [ 3.47873181e-01  4.10695696e+00]
     [ 5.75571477e-01  2.82786512e+00]
     [-3.78564209e-01  2.48611331e+00]
     [ 1.00240982e+00  3.91449356e+00]
     [ 3.28479111e-01  3.74326134e+00]
     [ 1.51334751e+00  2.77182865e+00]
     [ 9.62955832e-01  4.81651735e+00]
     [-6.48131311e-01  3.92258668e+00]
     [-1.85817286e-01  2.25299144e+00]
     [-2.81753540e-01  3.19250226e+00]
     [ 1.60171700e+00  4.31182480e+00]
     [-8.90413761e-01  2.89744067e+00]
     [ 1.58635542e-01  4.91175222e+00]
     [ 1.78851306e+00  3.87590241e+00]
     [ 1.10825253e+00  3.11820292e+00]
     [-1.49811316e+00  1.25389969e+00]
     [-3.27646345e-01  3.55048537e+00]
     [-6.19352221e-01  3.48040843e+00]
     [ 1.06147802e+00  4.51592302e+00]
     [ 2.40176529e-01  3.01918459e+00]
     [-6.62589788e-01  3.11936498e+00]
     [ 1.31588304e+00  2.66861415e+00]
     [-2.65876949e-01  3.51323223e+00]
     [ 9.55955267e-01  2.66442418e+00]
     [ 7.51409054e-01  4.37468624e+00]
     [ 1.74816525e+00  3.52251911e+00]
     [ 4.58441287e-01  2.69846559e+00]
     [ 6.83502078e-01  5.02861023e+00]
     [-1.52686751e+00  2.72911596e+00]
     [-8.63402545e-01  2.94489980e+00]
     [-1.38956833e+00  4.14784145e+00]
     [-1.06688237e+00  1.70743632e+00]
     [ 5.72761595e-01  2.73562527e+00]
     [-2.12888908e+00  5.72987616e-01]
     [-3.95522445e-01  4.41157103e+00]
     [ 6.36086285e-01  3.23032165e+00]
     [-2.67939597e-01  1.58512437e+00]
     [ 1.84608415e-01  2.55360651e+00]
     [-2.27766967e+00  2.36233926e+00]
     [-1.17371273e+00  3.34289455e+00]
     [-1.42427409e+00  1.45261967e+00]
     [ 1.00536183e-01  3.51610827e+00]
     [ 1.16399980e+00  4.80901051e+00]
     [-9.14171040e-01  2.80582809e+00]
     [ 3.93123209e-01  4.30892420e+00]
     [ 4.81700063e-01  5.64340448e+00]
     [ 1.73618102e+00  3.80866766e+00]
     [ 1.08188808e+00  3.53585935e+00]
     [ 1.04945910e+00  3.35987616e+00]
     [ 1.09308541e+00  3.28962564e+00]
     [ 1.28301501e+00  3.48777699e+00]
     [ 4.07559931e-01  3.32849169e+00]
     [ 1.84748280e+00  2.48712444e+00]
     [ 1.02546382e+00  2.75568676e+00]
     [-8.67931366e-01  4.04677677e+00]
     [ 2.27400374e+00  4.00509024e+00]
     [-2.02778988e-02  4.28144312e+00]
     [-5.22841737e-02  2.27995062e+00]
     [ 1.92388386e-01  3.95100331e+00]
     [-1.25785553e+00  1.39762282e+00]]
    [[-0.5131727   2.1856956 ]
     [ 0.54165345  3.3113148 ]
     [ 0.47503257  2.383504  ]
     [-0.6216325   2.9630225 ]
     [-2.1548796   3.4521687 ]
     [ 0.07632612  1.5396652 ]
     [ 0.03632626  3.807603  ]
     [ 0.6302923   2.9476213 ]
     [-0.46647555  2.6110272 ]
     [-0.9694342   1.9264345 ]
     [-0.12078202  3.4346988 ]
     [ 0.04558768  2.9481764 ]
     [-0.5248854   2.4323282 ]
     [ 1.5058922   4.8641863 ]
     [-0.71113616  2.460773  ]
     [ 0.10412053  1.8700296 ]
     [ 0.13601823  4.2752967 ]
     [ 0.69430745  3.7372513 ]
     [-0.04406321  2.6929715 ]
     [ 0.5779261   1.90228   ]
     [ 0.0425722   2.556339  ]
     [ 0.92457783  4.373241  ]
     [-0.24993701  3.4920347 ]
     [ 0.40254694  2.2323596 ]
     [ 1.7413974   4.526253  ]
     [-0.3969547   2.0910125 ]
     [ 0.8375148   2.0735612 ]
     [-0.7363629   1.224533  ]
     [-0.36603263  2.2838972 ]
     [ 0.34869578  3.2708397 ]
     [ 0.22174168  3.7880487 ]
     [ 2.125575    3.347968  ]
     [-1.6162122   2.253986  ]
     [-2.1820636   1.7232496 ]
     [-0.45225608  2.2338974 ]
     [ 0.36913162  4.626918  ]
     [ 1.9592822   3.439439  ]
     [-0.2134706   2.8446417 ]
     [ 0.32597944  2.9880104 ]
     [ 0.20980404  1.0831325 ]
     [-1.8429991   2.2369552 ]
     [-1.0092069   3.6219237 ]
     [ 0.04710719  4.2146845 ]
     [-0.36269286  4.402793  ]
     [ 2.1420672   3.2577407 ]
     [ 0.2093548   2.021334  ]
     [-0.15009886  3.8821633 ]
     [-1.2450775   2.910174  ]
     [ 1.0242422   4.4847975 ]
     [ 0.25089073  1.8419757 ]
     [-0.41495803  2.2647896 ]
     [-1.5449209   2.3380392 ]
     [-1.2209749   1.5585631 ]
     [-2.4833224   2.7663229 ]
     [ 2.265973    3.2679682 ]
     [ 0.31231862  1.1582814 ]
     [ 1.4676474   2.504069  ]
     [ 0.5056292   3.3574073 ]
     [ 0.91183025  4.1578627 ]
     [ 0.57764673  2.4407616 ]
     [ 0.86859286  4.374095  ]
     [ 0.38849762  3.2937422 ]
     [-0.69549364  4.1552444 ]
     [-0.75926536  1.4993583 ]
     [-0.8098742   3.1302025 ]
     [ 0.26821056  4.3346806 ]
     [ 0.04265249  3.3074322 ]
     [ 0.12317554  2.6987224 ]
     [-0.87047523  3.8263113 ]
     [-0.5673041   2.22412   ]
     [ 1.389103    3.0752983 ]
     [ 1.0415375   3.0037067 ]
     [-0.06375231  2.0348723 ]
     [ 0.06230587  2.336733  ]
     [-1.7058153   3.343202  ]
     [-0.91812617  5.073298  ]
     [-0.04376049  1.697662  ]
     [ 0.9577221   4.436241  ]
     [ 0.8310705   2.0644574 ]
     [ 0.07749289  3.3762739 ]
     [ 0.93991727  3.8324182 ]
     [-1.8460429   0.53364193]
     [ 0.4425154   3.7818933 ]
     [-0.19706652  2.5479395 ]
     [ 1.4711651   3.0372412 ]
     [ 1.9514488   2.9363756 ]
     [-0.48259333  1.9400855 ]
     [ 0.06688881  4.3178205 ]
     [ 0.15843105  2.5265813 ]
     [ 0.23291999  2.7545078 ]
     [-0.8288415   1.8662326 ]
     [ 0.1658639   3.1977475 ]
     [ 1.8487108   4.113743  ]
     [-0.29370576  3.4272227 ]
     [ 0.84895384  4.317551  ]
     [ 0.35618     2.0914018 ]
     [-0.48139128  2.911834  ]
     [ 0.81932396  3.1766143 ]
     [ 0.30741096  4.6534624 ]
     [ 0.5690362   2.6528249 ]]
    [[-7.45747507e-01  1.92949378e+00]
     [-1.08767223e+00  3.72886968e+00]
     [-1.13668728e+00  3.50325418e+00]
     [ 3.93780500e-01  5.24414301e+00]
     [ 4.89970922e-01  2.95536232e+00]
     [-1.79727614e+00  3.13662219e+00]
     [ 8.50762725e-01  5.08107567e+00]
     [-9.90527511e-01  3.56547904e+00]
     [ 9.10163105e-01  4.16456175e+00]
     [-1.13601303e+00  1.62071502e+00]
     [-1.19858747e-02  3.41061664e+00]
     [-1.94285274e-01  2.81571031e+00]
     [-9.66160893e-02  4.19248581e+00]
     [ 1.22491264e+00  4.41162443e+00]
     [-8.97670209e-01  4.02977943e+00]
     [ 4.87337559e-02  3.65142775e+00]
     [ 1.01243985e+00  4.87999201e+00]
     [ 4.99073446e-01  4.64624929e+00]
     [ 1.41278708e+00  3.89743352e+00]
     [ 5.61737776e-01  3.57618308e+00]
     [-2.21237764e-02  3.37213659e+00]
     [-7.28992045e-01  2.56220055e+00]
     [ 8.53898585e-01  3.60596752e+00]
     [-6.16417646e-01  3.13804173e+00]
     [ 1.21334636e+00  2.36677742e+00]
     [-8.29558909e-01  3.14476085e+00]
     [-4.41189677e-01  2.77874374e+00]
     [-4.73433167e-01  2.71108913e+00]
     [ 1.34609962e+00  3.69522452e+00]
     [ 4.28550214e-01  3.59700990e+00]
     [ 1.22572052e+00  4.50308466e+00]
     [ 7.45580196e-01  3.91565275e+00]
     [-1.72272074e+00  3.06358695e+00]
     [ 1.98206115e+00  4.37983847e+00]
     [ 1.09735441e+00  4.00146294e+00]
     [ 2.27176055e-01  2.94035888e+00]
     [ 2.24240422e+00  3.07742238e+00]
     [ 1.24874964e-01  6.98471725e-01]
     [-2.09015870e+00  2.17389441e+00]
     [-8.94584060e-01  2.27021837e+00]
     [-2.01028991e+00  9.91374612e-01]
     [-3.59830171e-01  2.61504745e+00]
     [-1.01634431e+00  9.29989874e-01]
     [-1.46873331e+00  2.25369263e+00]
     [ 4.65963900e-01  2.77860618e+00]
     [ 1.20677328e+00  3.84860229e+00]
     [ 5.85556626e-01  4.14991140e+00]
     [-5.09627104e-01  1.54764569e+00]
     [ 9.04966235e-01  2.97222996e+00]
     [-3.00523788e-01  2.36178589e+00]
     [ 8.04150254e-02  3.66863132e+00]
     [ 1.32427979e+00  3.80580974e+00]
     [-2.11637402e+00 -2.22319454e-01]
     [ 4.67921466e-01  5.38775682e+00]
     [-2.96473205e-01  2.64214873e+00]
     [-1.27694798e+00  3.38851738e+00]
     [ 9.19896662e-02  2.31148601e+00]
     [-2.51348197e-01  1.43276215e+00]
     [-2.10837674e+00  1.88156641e+00]
     [ 1.17106318e-01  1.90766847e+00]
     [-8.94448876e-01  4.48825550e+00]
     [ 1.19060600e+00  2.69796991e+00]
     [-8.60681534e-01  1.99721241e+00]
     [ 1.30936682e+00  2.72772503e+00]
     [-8.55676770e-01  3.43647265e+00]
     [ 1.07807922e+00  5.00360155e+00]
     [-9.87378776e-01  1.53052735e+00]
     [ 2.58814275e-01  3.17174435e+00]
     [ 2.76478052e-01  2.38935137e+00]
     [ 3.39522749e-01  3.85635900e+00]
     [-2.16353089e-01  3.06414533e+00]
     [ 1.31701779e+00  4.32305670e+00]
     [ 1.23184502e+00  3.81803107e+00]
     [ 2.22178735e-03  3.11521935e+00]
     [-1.09776723e+00  3.67949319e+00]
     [ 2.07892939e-01  2.89573622e+00]
     [-3.19762766e-01  2.76344085e+00]
     [ 5.94507277e-01  2.48062015e+00]
     [ 1.71619326e-01  3.34785891e+00]
     [ 2.35678732e-01  5.08504391e+00]
     [ 1.00529945e+00  3.64505625e+00]
     [-5.85084260e-01  3.13095093e+00]
     [-2.28351122e-03  4.27620602e+00]
     [-2.24701107e-01  5.08026886e+00]
     [ 2.19890571e+00  4.31772470e+00]
     [-1.13606644e+00  2.21801400e+00]
     [-5.11139214e-01  3.12210202e+00]
     [-9.11824584e-01  3.81575584e+00]
     [ 5.50838947e-01  3.25031590e+00]
     [ 1.24414980e+00  4.42438984e+00]
     [-5.31336010e-01  3.08257151e+00]
     [-1.25404167e+00  1.84299839e+00]
     [ 1.39890134e-01  3.25782204e+00]
     [-4.03687418e-01  2.01760912e+00]
     [ 4.32173401e-01  2.10083604e+00]
     [ 7.86111891e-01  3.60874152e+00]
     [ 5.78634202e-01  3.10896444e+00]
     [-2.18628004e-01  4.23619938e+00]
     [ 3.63553584e-01  4.04708290e+00]
     [-3.85930300e-01  2.10300875e+00]]
    [[-8.3511806e-01  3.3130219e+00]
     [ 7.8957751e-02  1.1121898e+00]
     [ 4.9041836e-03  3.4631639e+00]
     [ 4.0231872e-01  2.1794212e+00]
     [-2.2084332e+00  1.8456713e+00]
     [-1.1828388e+00  2.1643791e+00]
     [ 3.5543874e-01  3.0304549e+00]
     [ 4.2468771e-01  3.6543586e+00]
     [ 1.6244322e+00  4.6566963e+00]
     [ 1.3221059e+00  4.3290329e+00]
     [ 2.1963162e+00  3.7613833e+00]
     [ 5.4139119e-01  4.3417130e+00]
     [-2.6184422e-01  3.4307382e+00]
     [ 1.3004571e+00  3.3832927e+00]
     [-6.1723024e-01  2.1255276e+00]
     [-2.2981093e+00  1.3001673e+00]
     [ 3.6456756e-02  2.8607204e+00]
     [ 1.6923267e-01  2.9304631e+00]
     [-5.1147473e-01  3.3981650e+00]
     [ 1.4470932e-02  3.3106678e+00]
     [-7.8492159e-01  2.0051203e+00]
     [-1.1950346e+00  2.4204476e+00]
     [-1.8784918e-01  3.8362257e+00]
     [ 1.6837205e+00  4.5864496e+00]
     [ 1.4440355e+00  4.3388410e+00]
     [ 2.3968439e-01  3.1059270e+00]
     [-1.9314853e+00  2.2773173e+00]
     [-5.6059122e-01  1.6134869e+00]
     [ 4.1300377e-01  4.6214862e+00]
     [ 4.3277794e-01  3.7498770e+00]
     [-9.8184240e-01  1.3465358e+00]
     [ 1.1898744e+00  5.3195920e+00]
     [ 5.4484433e-01  4.2977719e+00]
     [ 5.6570971e-01  3.5142200e+00]
     [-1.8687811e-01  3.0387733e+00]
     [ 6.3466823e-01  3.3112202e+00]
     [-1.0578102e+00  2.7327402e+00]
     [ 1.9710836e-01  4.5511837e+00]
     [-8.6931711e-01  2.1546843e+00]
     [ 1.0269258e+00  4.7631516e+00]
     [-1.6303749e-01  2.4115181e+00]
     [ 3.3107948e-01  2.3490138e+00]
     [ 9.4079435e-01  4.0993414e+00]
     [-5.7226276e-01  2.9833000e+00]
     [ 5.8911514e-01  4.0229902e+00]
     [ 5.4663056e-01  3.5697455e+00]
     [ 7.6510078e-01  4.6342087e+00]
     [-1.5664629e+00  1.2563436e+00]
     [-3.9457332e-02  3.1830750e+00]
     [ 9.7694957e-01  3.5007594e+00]
     [-1.4709567e+00  1.0654777e+00]
     [ 8.2624072e-01  4.6343575e+00]
     [-4.7707140e-01  2.7078667e+00]
     [ 1.4533507e+00  3.3834302e+00]
     [ 1.8268016e-01  3.6289628e+00]
     [-9.8259723e-01  7.7657533e-01]
     [ 1.5384881e+00  3.9735637e+00]
     [-6.7490035e-01  3.8066361e+00]
     [-7.4229276e-01  2.8926249e+00]
     [-1.0548276e+00  2.8292160e+00]
     [-9.8011994e-01  4.3168020e+00]
     [-1.1509236e+00  1.9497308e+00]
     [ 2.6070714e+00  3.9016869e+00]
     [-1.4375666e+00  2.4023731e+00]
     [ 5.0776017e-01  2.9874825e+00]
     [-5.6201094e-01  2.5544569e+00]
     [ 1.4625587e-01  1.6592095e+00]
     [ 7.3414809e-01  2.7038217e+00]
     [ 8.1629628e-01  3.2851090e+00]
     [ 1.4170680e+00  2.7376013e+00]
     [ 4.3948099e-01  3.4995840e+00]
     [ 6.5291780e-01  3.1095836e+00]
     [ 1.2851719e+00  2.9896801e+00]
     [-5.2569646e-01  2.1186967e+00]
     [ 8.8507634e-01  2.9571698e+00]
     [ 1.0357240e-01  3.0108299e+00]
     [-7.5250620e-01  2.4436855e+00]
     [ 6.4428276e-01  3.5595379e+00]
     [-1.0334288e+00  1.9288198e+00]
     [-2.5684384e-01  2.4347286e+00]
     [ 1.2763475e+00  3.0365555e+00]
     [ 3.1096146e-01  2.4207678e+00]
     [-1.1716917e+00  4.2947736e+00]
     [-1.2822479e+00  2.2470994e+00]
     [-7.0153528e-01  2.5864956e+00]
     [ 2.8417590e-01  2.1783965e+00]
     [-1.0151746e+00  1.8269103e+00]
     [-5.4143518e-01  1.8226795e+00]
     [-5.4584235e-01  4.0904117e+00]
     [ 1.4016334e+00  3.3268845e+00]
     [ 1.0148395e+00  3.1402049e+00]
     [ 1.6227326e+00  2.9768670e+00]
     [-9.6379465e-01  2.8879175e+00]
     [-5.7144976e-01  3.6240599e+00]
     [-1.4864687e+00  6.7260683e-01]
     [ 1.3310981e+00  2.8207963e+00]
     [-6.6056192e-01  1.7040930e+00]
     [-1.5922701e+00  2.3259258e+00]
     [ 1.3482913e-01  6.3625020e-01]
     [-6.8857640e-01  2.7618418e+00]]
    [[ 1.7863635   4.79653   ]
     [-0.31407362  3.0627286 ]
     [ 0.56990546  4.552036  ]
     [-1.9636598   1.8244057 ]
     [-0.8897409   2.4821997 ]
     [ 0.18278664  2.779035  ]
     [ 0.08372666  2.4667742 ]
     [ 1.2416011   2.1057432 ]
     [ 1.3489227   3.3496711 ]
     [ 0.01191122  3.6821105 ]
     [ 0.05584034  1.7883812 ]
     [ 1.2270534   4.1256185 ]
     [-0.39773148  3.3840582 ]
     [ 0.5837845   3.6922662 ]
     [ 1.3533268   2.8685534 ]
     [ 0.08456658  3.1834898 ]
     [ 1.5395782   3.3766665 ]
     [ 0.1635117   3.7665782 ]
     [ 1.39173     3.966737  ]
     [-0.29502773  1.7691272 ]
     [-0.8319029   1.2813635 ]
     [ 0.19627412  2.6373377 ]
     [-0.376385    3.9902754 ]
     [-1.3909907   3.3070211 ]
     [ 0.26376787  2.5498269 ]
     [-1.4210479   3.3921633 ]
     [-0.3812875   1.7233107 ]
     [-1.5968983   2.6216702 ]
     [ 1.8016335   3.2721677 ]
     [ 0.13751511  2.8521788 ]
     [-2.7405803   2.2244794 ]
     [ 0.74130756  3.6864815 ]
     [ 0.07325628  2.0225377 ]
     [ 2.3743298   4.0038004 ]
     [-1.381544    1.0336157 ]
     [ 0.32385352  2.0597332 ]
     [ 1.2483566   2.7640655 ]
     [-0.7004835   2.6053886 ]
     [-0.35079882  2.9056728 ]
     [-0.7084332   2.1574783 ]
     [-0.63016224  0.86536604]
     [ 1.123842    4.645472  ]
     [-0.8462602   3.0548997 ]
     [-0.13126358  4.4002676 ]
     [ 0.4493283   3.705882  ]
     [ 0.17229189  3.4592605 ]
     [ 0.6880056   3.841916  ]
     [ 0.17161338  2.686141  ]
     [-0.7865781   2.6580887 ]
     [-0.15234806  3.4475327 ]
     [-0.21933444  3.634728  ]
     [-0.974547    1.6986395 ]
     [-0.776432    3.187246  ]
     [-1.6025534   1.3676683 ]
     [-0.03125897  3.8568192 ]
     [ 0.7931728   3.378763  ]
     [-0.6482001   2.207293  ]
     [-0.77956027  1.045709  ]
     [-0.12156735  3.2968988 ]
     [-0.84672624  1.9836745 ]
     [-0.56551987  3.478398  ]
     [ 1.3801094   5.813332  ]
     [ 0.58030194  4.8474574 ]
     [ 0.7163943   4.7304134 ]
     [-1.0702991   2.5264578 ]
     [ 1.5270828   0.84998506]
     [-2.4819221   0.51591474]
     [-1.4309479   2.9545996 ]
     [-0.3444917   2.8563411 ]
     [-0.80535305  1.5835028 ]
     [-0.2689946   3.0891683 ]
     [ 1.2650504   4.3519464 ]
     [ 0.5954505   2.3934965 ]
     [ 0.6796533   4.004188  ]
     [-1.133988    3.8965628 ]
     [-0.95105296  2.9754238 ]
     [-1.7922817   2.3563962 ]
     [-1.2909307   1.9761242 ]
     [-0.63593495  3.2226138 ]
     [-1.2761277   2.402793  ]
     [-0.49699032  2.837629  ]
     [-0.8561806   3.1301672 ]
     [-1.2046157   2.3295784 ]
     [-1.0937161   1.6025289 ]
     [-0.11089017  2.3997009 ]
     [-0.423547    1.1616238 ]
     [ 1.3638089   4.9130955 ]
     [-1.1609106   3.8003252 ]
     [-0.09453166  2.9629765 ]
     [-0.6255531   2.8230016 ]
     [-0.40369383  2.587159  ]
     [-1.4162686   1.5297068 ]
     [-0.28897983  2.3537006 ]
     [ 0.28204814  3.7242968 ]
     [-1.1867932   3.1212094 ]
     [-1.2976067   2.3756268 ]
     [ 0.7286529   2.6856518 ]
     [ 0.5506795   4.497886  ]
     [ 1.5229568   1.9026766 ]
     [ 0.68416435  2.2996118 ]]
    [[-0.4618204   1.2013518 ]
     [-0.27616245  4.3682857 ]
     [-0.63986623  1.4917578 ]
     [-0.29892743  3.036057  ]
     [ 2.349086    5.008653  ]
     [-0.14916751  3.401797  ]
     [ 0.01212407  2.9744375 ]
     [ 0.36038414  3.0873523 ]
     [-0.01934161  3.0234919 ]
     [-0.95973086  2.607246  ]
     [-0.86110437  1.3464444 ]
     [-1.4954002   1.7249864 ]
     [-0.45514995  2.712714  ]
     [ 0.47986132  2.1929626 ]
     [-0.7671452   2.2247245 ]
     [ 0.671512    3.3022878 ]
     [-0.07531943  3.197496  ]
     [-0.63787115  2.1007018 ]
     [ 1.0382586   4.9116893 ]
     [ 1.2228609   3.5623996 ]
     [ 0.7331913   3.7090864 ]
     [-0.15231304  2.072188  ]
     [ 1.1843057   3.4271348 ]
     [-0.06120403  3.1281662 ]
     [ 1.5915234   2.2841077 ]
     [-0.20315312  4.45888   ]
     [ 0.26802683  3.0880272 ]
     [ 0.19356194  2.5339384 ]
     [-0.09838138  0.74249035]
     [ 0.31534085  2.508943  ]
     [-0.7137071   3.0914156 ]
     [-1.2107245   2.8805802 ]
     [ 0.03702638  2.2439227 ]
     [ 0.03039929  5.025916  ]
     [-1.5583494   1.469511  ]
     [-0.24684812  2.5163631 ]
     [-0.2048628   4.6624146 ]
     [ 0.8977449   3.1823707 ]
     [ 0.02346044  3.1653023 ]
     [-1.6220772   2.338356  ]
     [ 0.5596212   3.1852038 ]
     [ 1.2487915   3.245304  ]
     [ 0.48497465  3.7335396 ]
     [-0.8553009   4.428351  ]
     [-2.059667    0.9973001 ]
     [ 0.35062265  3.1730576 ]
     [ 0.2612004   3.2630813 ]
     [-1.0756731   1.8077908 ]
     [ 0.04758114  3.044509  ]
     [-0.11608587  4.295116  ]
     [-0.7892694   2.9807813 ]
     [-0.10497541  3.3131135 ]
     [ 1.1253214   4.1350136 ]
     [-0.9365086   1.3241115 ]
     [-0.14211473  2.0511816 ]
     [ 0.99446714  3.9295928 ]
     [ 1.85        4.2799087 ]
     [-1.4445287   2.3536015 ]
     [-0.11478493  2.121549  ]
     [-1.7229207   2.4259825 ]
     [-0.55178916  3.3382282 ]
     [ 1.8588021   3.0685976 ]
     [-0.34723583  3.387423  ]
     [-1.0264714   3.562431  ]
     [ 2.0559103   4.2731557 ]
     [ 1.2382452   2.7123156 ]
     [-0.19101454  3.0562727 ]
     [-0.44681817  5.238468  ]
     [ 0.809988    3.2142982 ]
     [ 1.1057607   5.430016  ]
     [ 1.1471101   4.6492386 ]
     [ 0.40279266  2.8048885 ]
     [ 0.28618208  3.5086756 ]
     [ 1.4489715   5.1431623 ]
     [ 0.743345    3.5607178 ]
     [ 0.49831846  3.0600834 ]
     [ 1.7917972   4.607408  ]
     [-1.6560009   1.4545859 ]
     [ 0.21354212  3.269634  ]
     [-1.431198    3.5260735 ]
     [ 0.5412461   2.7050974 ]
     [-1.2422043   2.1439316 ]
     [ 1.1179297   3.5625117 ]
     [-0.04760082  3.1655545 ]
     [-0.30208233  2.0163672 ]
     [ 1.2218527   5.9799795 ]
     [-1.6874931   1.8516155 ]
     [-0.8304958   3.2803924 ]
     [ 0.7635943   2.82629   ]
     [-1.1292082   3.840929  ]
     [ 0.0598648   2.4103458 ]
     [ 0.6122741   3.222043  ]
     [ 0.8270377   2.560395  ]
     [ 0.2602563   3.2750626 ]
     [-1.1407125   1.5429978 ]
     [-0.09863055  2.9953423 ]
     [-0.68888277  2.4938476 ]
     [-0.6031654   1.8827139 ]
     [-0.6846992   3.8312705 ]
     [ 0.2503429   2.9804487 ]]
    [[-0.02910735  3.5068524 ]
     [ 1.8223877   3.8631291 ]
     [-0.56389695  3.5238214 ]
     [ 0.260865    3.1099842 ]
     [ 1.4666376   3.6525042 ]
     [ 2.1682975   2.9372604 ]
     [ 0.77595687  3.943013  ]
     [ 0.0482884   2.709109  ]
     [-0.31855357  2.5825503 ]
     [-0.31637678  4.4797425 ]
     [ 1.7086155   4.257355  ]
     [ 1.4252887   4.940542  ]
     [-1.8508196   2.1697521 ]
     [ 1.4533707   3.011468  ]
     [-0.05817458  4.881037  ]
     [ 0.3651233   2.424962  ]
     [-0.34952596  2.4315746 ]
     [-0.31096685  1.8454756 ]
     [ 1.0311514   3.3215904 ]
     [-1.3919983   1.8891969 ]
     [ 0.04580094  2.2376418 ]
     [ 0.95562404  2.4380293 ]
     [-0.5981436   2.1365209 ]
     [ 0.53700536  3.4147513 ]
     [ 0.6899854   2.246017  ]
     [ 0.18371686  4.618513  ]
     [-0.07145002  1.9459544 ]
     [-0.16878092  4.1516466 ]
     [ 0.41851008  3.035611  ]
     [-0.17578988  4.178868  ]
     [ 0.4801851   1.9485347 ]
     [-0.4441043   3.6643791 ]
     [ 0.5147916   3.724424  ]
     [ 0.18249018  4.3369336 ]
     [-0.813023    1.2138884 ]
     [-1.7049694   2.3191998 ]
     [-0.8158404   2.950165  ]
     [-0.7181066   2.6016598 ]
     [-0.9792426   2.4394834 ]
     [ 2.2907534   3.2354279 ]
     [-1.6764649   3.091342  ]
     [-1.6089274   1.935787  ]
     [-1.7764065   2.8818908 ]
     [ 1.0835662   4.511745  ]
     [-0.73038065  2.782276  ]
     [-0.40501982  4.1761913 ]
     [ 1.099578    4.1340694 ]
     [-0.12844267  3.145026  ]
     [-0.40967196  2.751304  ]
     [ 0.13587014  3.9084475 ]
     [ 0.23881096  4.4063015 ]
     [-0.42502278  1.1851095 ]
     [ 0.9222052   2.4057102 ]
     [ 1.1177031   3.6746688 ]
     [ 0.69422835  3.135154  ]
     [-0.7651956   2.5927215 ]
     [ 0.58085144  1.8594135 ]
     [ 1.2011812   4.0618515 ]
     [-0.6255496   1.7259754 ]
     [-0.7209657   2.7658174 ]
     [ 1.6287838   4.366156  ]
     [-2.1900063   1.0695554 ]
     [-1.1545849   4.0167766 ]
     [-0.43041682  3.7886972 ]
     [ 0.39758274  3.9403226 ]
     [-0.6411548   3.9820151 ]
     [ 0.20060205  2.910896  ]
     [-2.4611807   0.56699616]
     [-0.03492371  3.4146118 ]
     [-0.42456084  2.0803885 ]
     [-0.25851655  3.3661761 ]
     [-0.7611961   3.516283  ]
     [ 0.42445853  3.7787006 ]
     [ 0.35530132  3.053439  ]
     [ 1.5467415   4.377801  ]
     [ 1.3067386   5.2692275 ]
     [ 1.2011803   3.9377267 ]
     [-1.8060073   3.5906298 ]
     [ 1.2304215   2.4885142 ]
     [-0.9915468   2.0299337 ]
     [ 2.266353    3.8220015 ]
     [-0.34578693  2.2868247 ]
     [ 0.5501547   3.5767238 ]
     [ 0.12473029  3.3439765 ]
     [ 0.04798579  2.1959996 ]
     [-1.6812086   1.8959962 ]
     [-0.7232179   4.5579495 ]
     [-0.71347284  4.370815  ]
     [-0.6358579   4.0018053 ]
     [ 0.81596655  3.5321598 ]
     [-0.08725056  2.7316067 ]
     [ 1.4500487   2.5751603 ]
     [-0.5524632   1.6748534 ]
     [ 1.019364    2.2151396 ]
     [-0.08313902  2.1578207 ]
     [-0.12663057  4.414378  ]
     [ 1.0388476   3.460742  ]
     [-0.7227144   1.9187353 ]
     [ 0.69185114  4.042582  ]
     [-0.34348178  3.5083377 ]]
    [[-0.8537878   2.449589  ]
     [ 0.01880142  1.6266248 ]
     [-0.77344203  2.05402   ]
     [ 1.0840265   2.6311183 ]
     [-0.48460686  2.477495  ]
     [ 0.34154263  4.0335355 ]
     [-1.1014476   3.6844046 ]
     [-0.4963851   3.1227446 ]
     [-1.1859747   3.4929001 ]
     [-0.25539714  1.973333  ]
     [-0.21666138  2.6418285 ]
     [-0.11487059  2.9512503 ]
     [-2.330183    0.32828093]
     [ 0.13031249  3.0482168 ]
     [ 2.6951632   4.317564  ]
     [-0.27317974  3.2027364 ]
     [ 1.0964533   3.7466834 ]
     [-0.5150751   1.1097436 ]
     [-1.3858037   1.0911212 ]
     [ 1.0114597   3.7251582 ]
     [ 2.025805    5.023686  ]
     [-0.19381154  1.8588245 ]
     [ 1.359649    3.4204972 ]
     [ 0.5295934   2.7090476 ]
     [ 1.8940952   4.7037787 ]
     [ 0.09420161  3.3709219 ]
     [-0.97568786  2.5872574 ]
     [ 0.10762304  3.3777359 ]
     [-0.640821    1.9093904 ]
     [-1.3747602   1.8855559 ]
     [-0.60583943  2.7274163 ]
     [-0.7033106   2.8678896 ]
     [-0.98605514  2.6904862 ]
     [-0.5517311   3.187774  ]
     [-0.5477513   2.488178  ]
     [ 1.1367114   2.8288906 ]
     [ 1.2943444   2.3412764 ]
     [-0.9283618   0.5404    ]
     [ 0.19271539  2.8564768 ]
     [-2.5845783   1.8290311 ]
     [-0.52002126  3.425175  ]
     [ 1.0995066   3.9934192 ]
     [ 1.0864195   4.158202  ]
     [ 0.08679556  2.8227978 ]
     [ 0.7841934   2.87856   ]
     [ 0.34711555  3.879863  ]
     [ 0.02938416  2.8553789 ]
     [-0.46289167  3.512753  ]
     [ 0.5773844   3.4401903 ]
     [ 1.0205414   2.722846  ]
     [ 1.230548    1.9024521 ]
     [-0.56242335  3.1249926 ]
     [-0.5746199   2.8937967 ]
     [-0.76084584  2.4968696 ]
     [-0.23637398  2.982447  ]
     [-0.70883     2.7522788 ]
     [ 0.34597468  4.091976  ]
     [ 2.8705838   3.232889  ]
     [ 0.22237839  3.2346523 ]
     [ 0.25345808  3.761852  ]
     [-0.31648225  3.5807698 ]
     [-0.2862347   3.5099964 ]
     [ 0.08302414  2.5407004 ]
     [-1.2918226   1.9979882 ]
     [ 0.48961422  3.1868727 ]
     [ 0.3327839   4.1158276 ]
     [-0.21806817  2.2482822 ]
     [ 0.2878842   2.7273755 ]
     [-0.6821302   1.9201206 ]
     [ 1.4162747   2.2513707 ]
     [-0.29314077  2.745519  ]
     [ 0.27974877  2.9823005 ]
     [-1.0265725   1.87279   ]
     [ 0.90853655  3.4233966 ]
     [-0.2873372   2.3909318 ]
     [ 1.160374    5.6014514 ]
     [ 0.63526547  3.8999844 ]
     [-0.6765919   0.6778094 ]
     [-0.17027308  3.0021904 ]
     [ 0.1926218   3.7003298 ]
     [-1.1020985   2.0235977 ]
     [-0.38641346  1.7183793 ]
     [-1.167081    2.2150562 ]
     [-0.28054824  2.3442707 ]
     [ 0.52922934  4.3694305 ]
     [ 1.0554943   3.8365173 ]
     [-0.44607306  1.4377086 ]
     [-1.6166787   2.8122807 ]
     [ 1.3202615   4.69913   ]
     [ 1.650014    4.955726  ]
     [-1.3923695   4.469551  ]
     [-1.1478387   1.535698  ]
     [ 0.45455843  3.682971  ]
     [ 1.6416672   4.537575  ]
     [ 0.1961154   3.5580475 ]
     [-2.6517472   1.8097657 ]
     [-1.5690213   1.1302787 ]
     [ 0.98371667  3.3008304 ]
     [ 0.3224021   3.5713205 ]
     [ 0.8796779   4.8000703 ]]
    [[ 3.928823    1.3620331 ]
     [ 2.3317158   2.0229666 ]
     [ 4.330917    1.1257424 ]
     [ 3.4040363   0.8335637 ]
     [ 1.513559   -0.23272327]
     [ 1.6425614  -0.39369848]
     [ 3.748691   -0.09328412]
     [ 2.595826    0.31926912]
     [ 2.9115775   0.6428468 ]
     [ 1.9619447   0.9282704 ]
     [ 1.3754207   0.5005406 ]
     [ 0.85447574 -0.977847  ]
     [ 2.0948148   0.33113033]
     [ 2.6391668  -1.7379811 ]
     [ 2.8662326  -0.71905255]
     [ 3.7557445   1.5145541 ]
     [ 3.5548327   0.9651009 ]
     [ 4.178475    0.9770956 ]
     [ 2.001808   -0.45772135]
     [ 2.4716654  -1.2221941 ]
     [ 5.1138167   1.0616674 ]
     [ 0.8135871  -0.9497192 ]
     [ 2.5799723   0.6418476 ]
     [ 3.322284   -0.7619984 ]
     [ 4.6278377  -0.39142665]
     [ 4.171888    0.15870486]
     [ 2.5957859  -0.21809644]
     [ 3.8265734   1.0585005 ]
     [ 4.15547     2.296187  ]
     [ 3.3144896  -0.10151809]
     [ 5.0382423   1.4618917 ]
     [ 1.5292554  -2.0099144 ]
     [ 3.646636    0.13934392]
     [ 3.9208856  -0.29260698]
     [ 4.6396356   0.2867713 ]
     [ 3.291534    0.3667988 ]
     [ 5.074579    0.30042174]
     [ 1.6920003  -0.09104703]
     [ 3.7283347  -1.3770822 ]
     [ 3.7583916  -0.73212785]
     [ 1.8926404   0.7775695 ]
     [ 4.4812503   2.250077  ]
     [ 2.7377224   0.36171037]
     [ 3.6019945   0.62560093]
     [ 2.9702902  -0.13145761]
     [ 3.8442826  -0.919941  ]
     [ 3.752099   -0.5195875 ]
     [ 2.1976135  -0.4905463 ]
     [ 2.0158236   0.88241786]
     [ 3.289664   -0.42491257]
     [ 3.026781    0.09144603]
     [ 4.3116064   0.72765243]
     [ 2.084442   -1.3022453 ]
     [ 4.448817    1.1896987 ]
     [ 3.5775762   1.4890645 ]
     [ 2.3385391  -1.4080153 ]
     [ 3.790548    1.1929394 ]
     [ 4.443527    0.97655606]
     [ 2.8351216  -0.98178774]
     [ 2.398641   -1.2340032 ]
     [ 3.7917712   1.2943705 ]
     [ 1.0125283  -0.7430866 ]
     [ 3.3845263   0.35828346]
     [ 3.3345768   0.65008825]
     [ 3.0586746  -1.1944106 ]
     [ 1.6261597  -1.1396023 ]
     [ 3.956772    2.3390672 ]
     [ 3.3561766  -0.8179054 ]
     [ 2.298301   -0.9100515 ]
     [ 2.189268   -1.6124306 ]
     [ 2.0722616  -0.26597494]
     [ 2.2512274  -0.95902807]
     [ 1.8004699  -0.19600594]
     [ 3.0045073   0.04272702]
     [ 4.3605757  -0.27616385]
     [ 3.309179    1.5816587 ]
     [ 1.2335403  -1.1244756 ]
     [ 2.202303   -0.31556517]
     [ 1.9591353  -0.9446498 ]
     [ 3.7050576   0.58466524]
     [ 2.9718554   0.70061666]
     [ 3.4476974  -0.24539913]
     [ 3.2743385   0.9758096 ]
     [ 2.3483248  -1.2213908 ]
     [ 3.9644723   1.9158261 ]
     [ 3.2205195   1.8784361 ]
     [ 1.4972901  -0.6188279 ]
     [ 2.803916    1.2189558 ]
     [ 3.6339517  -0.31439283]
     [ 4.900598    0.5352751 ]
     [ 3.262531   -0.94281626]
     [ 2.1497924  -0.6783416 ]
     [ 2.5435033  -0.39923868]
     [ 1.4324584   0.8774106 ]
     [ 0.85392064 -1.030274  ]
     [ 1.7394252  -0.93622184]
     [ 1.3650808   0.5113386 ]
     [ 2.6776216  -0.26551706]
     [ 3.381976   -0.09753238]
     [ 1.5134008  -1.76032   ]]
    [[ 3.8335392  -0.0701701 ]
     [ 3.306509   -0.50366414]
     [ 4.465519    2.1502166 ]
     [ 4.8482556  -0.24836232]
     [ 4.497626    1.6899081 ]
     [ 1.9710735   0.20218243]
     [ 2.8868597   0.4440037 ]
     [ 2.5051095   0.7285787 ]
     [ 2.6244137  -0.5855532 ]
     [ 1.5460836  -0.04010001]
     [ 2.441981   -0.46771446]
     [ 3.496405    0.93781155]
     [ 2.543149    0.5219893 ]
     [ 3.4956515  -0.4164391 ]
     [ 1.9531376   0.9348147 ]
     [ 3.0383258   0.4499374 ]
     [ 1.946809   -0.20610514]
     [ 4.2169614   0.0549956 ]
     [ 3.115457   -0.04263633]
     [ 3.0214431  -0.02806622]
     [ 3.011451   -0.6909199 ]
     [ 1.6954521  -1.0033875 ]
     [ 4.432946    0.27154428]
     [ 3.7224624   1.5582365 ]
     [ 3.4183168  -1.1841305 ]
     [ 2.3223295  -0.76188993]
     [ 2.186619   -0.5508516 ]
     [ 4.35317    -0.62788606]
     [ 2.3296878  -0.89556444]
     [ 3.8184886   0.18910319]
     [ 3.5196693   0.31682506]
     [ 2.465027    0.3550515 ]
     [ 2.2034428   0.02251463]
     [ 3.7725728   0.37656865]
     [ 2.2268004  -0.12772995]
     [ 2.2677968  -2.2509553 ]
     [ 1.6818334  -0.9748888 ]
     [ 2.1502616  -1.3155907 ]
     [ 2.5605493   0.47355446]
     [ 3.4151714  -0.33548895]
     [ 3.5851226   0.03432353]
     [ 1.6338352  -0.26265898]
     [ 3.9910285  -0.23915243]
     [ 2.5115664   0.2624197 ]
     [ 1.8788121  -0.8741826 ]
     [ 3.7136173   0.40526474]
     [ 2.9169219   0.53893155]
     [ 2.2052872  -0.27719253]
     [ 2.7400186  -1.3528277 ]
     [ 1.914339   -1.2063566 ]
     [ 2.513627   -1.153968  ]
     [ 4.12469    -0.09507499]
     [ 2.5262709  -0.29853785]
     [ 2.5781238  -0.28406414]
     [ 2.2195187  -0.3321689 ]
     [ 2.2773976   0.24664274]
     [ 3.7537606   0.23216072]
     [ 2.1830325  -1.3675932 ]
     [ 2.6142728  -0.4598489 ]
     [ 4.1145997  -0.31908903]
     [ 1.9737144  -1.8509972 ]
     [ 2.1708348  -0.8672622 ]
     [ 4.3542695   0.6578383 ]
     [ 3.08193     0.165124  ]
     [ 2.3302119  -1.0200257 ]
     [ 2.2501855  -0.9701599 ]
     [ 2.8474443   0.3663018 ]
     [ 2.7653162  -0.5522604 ]
     [ 2.6571586  -0.21785276]
     [ 3.030664   -0.82053035]
     [ 3.206942    0.92164195]
     [ 2.176525   -0.4128119 ]
     [ 3.171417   -0.02301665]
     [ 3.6761448  -1.7359494 ]
     [ 3.8381233  -0.6225859 ]
     [ 3.3594563  -0.6331386 ]
     [ 5.067414    0.6292897 ]
     [ 2.1679149  -0.7187888 ]
     [ 3.9800878   0.32470092]
     [ 4.155967    0.16757722]
     [ 4.402792    1.655572  ]
     [ 2.385798   -0.96537197]
     [ 3.0712028   0.40169072]
     [ 3.557714   -0.9361033 ]
     [ 3.999744    1.8880168 ]
     [ 3.2226894  -0.34794113]
     [ 3.3638716  -0.6968764 ]
     [ 3.987793    0.0358168 ]
     [ 2.2065008  -0.36983436]
     [ 2.4190283  -0.44795617]
     [ 3.525535   -0.5105058 ]
     [ 2.0366566   0.90473926]
     [ 1.412492   -1.3971857 ]
     [ 3.7203116  -0.34783557]
     [ 2.5259612   1.7353182 ]
     [ 1.6736203  -1.1548142 ]
     [ 2.93004     0.94094145]
     [ 2.627482   -0.68207914]
     [ 2.852694    0.5286177 ]
     [ 2.1987505  -0.09942046]]
    [[ 3.5645342   0.1467242 ]
     [ 2.7282639   0.01147449]
     [ 3.3912535  -0.1434701 ]
     [ 4.419083    1.031425  ]
     [ 2.8355598  -0.5039514 ]
     [ 3.640277   -0.15694852]
     [ 2.8598602  -1.1291453 ]
     [ 2.4705968  -0.8033735 ]
     [ 1.897583    0.5868604 ]
     [ 4.0396395   0.52469575]
     [ 4.1988883   1.5777309 ]
     [ 3.419871    0.6341201 ]
     [ 2.901591   -1.6065966 ]
     [ 1.7810237  -1.0238289 ]
     [ 2.5973024  -1.9674779 ]
     [ 2.5467744  -1.3021626 ]
     [ 1.8355759  -0.14664033]
     [ 3.1164484  -0.3255351 ]
     [-0.4249643  -1.2797607 ]
     [ 3.5025103   0.28159234]
     [ 4.08993    -0.48016846]
     [ 4.604189    1.1432639 ]
     [ 2.6646173  -0.6699013 ]
     [ 2.846708    0.12315886]
     [ 3.7153134  -0.3037092 ]
     [ 1.0144572   0.0669251 ]
     [ 4.654311    0.5135212 ]
     [ 0.7111814  -0.9996596 ]
     [ 4.48558     0.6786507 ]
     [-0.06926879 -0.8287759 ]
     [ 4.431898    0.0307545 ]
     [ 2.5324974  -1.1539311 ]
     [ 3.7646332  -0.05629225]
     [ 3.8389037  -1.1132933 ]
     [ 3.8075218  -0.09507743]
     [ 4.0109057  -0.5873016 ]
     [ 0.63913274 -1.3085163 ]
     [ 3.6752107  -1.9995929 ]
     [ 3.275931    0.6296726 ]
     [ 3.6841364   1.0851824 ]
     [ 2.2460392  -0.13981318]
     [ 3.1422913  -0.4705364 ]
     [ 3.2698073  -0.6626592 ]
     [ 2.397163    0.2792267 ]
     [ 4.8814793   1.176065  ]
     [ 4.5263987  -0.49435455]
     [ 3.197207    0.68622094]
     [ 3.7216396  -1.0737369 ]
     [ 2.7737987  -1.3051057 ]
     [ 3.5681736   0.21782272]
     [ 5.026884    1.3246055 ]
     [ 2.8039312   1.8849262 ]
     [ 2.7789474  -1.0123284 ]
     [ 2.3978028  -0.830495  ]
     [ 3.235822    0.15993075]
     [ 0.72595847 -1.3147918 ]
     [ 1.9341357  -0.07247656]
     [ 2.3293178   0.7258912 ]
     [ 2.8710115  -0.8762577 ]
     [ 3.8297493  -0.8033478 ]
     [ 3.3772206  -0.7973498 ]
     [ 2.061364   -1.1370319 ]
     [ 2.3132408  -1.2554325 ]
     [ 2.761693   -0.69446325]
     [ 3.630874   -0.11783221]
     [ 4.842836    0.11427946]
     [ 3.0715148   0.71502185]
     [ 3.707539    1.2354287 ]
     [ 3.9398563   0.65840954]
     [ 4.494743    1.3626889 ]
     [ 2.476967    0.2392347 ]
     [ 2.6494088   2.025446  ]
     [ 3.4366717   0.552524  ]
     [ 2.271925   -0.6187304 ]
     [ 4.1500525   1.5775112 ]
     [ 3.7325974  -0.36769527]
     [ 3.8892105   0.3666851 ]
     [ 3.1637142   1.080079  ]
     [ 2.5143611   0.26467738]
     [ 0.4148502   0.09180085]
     [ 3.4128392   0.4541884 ]
     [ 4.318837    0.65668154]
     [ 3.4314418   1.8653977 ]
     [ 4.030431   -0.5103024 ]
     [ 3.7808475   0.07425141]
     [ 3.0928047   1.287095  ]
     [ 4.1298747   0.39247626]
     [ 2.1812067  -0.21604422]
     [ 2.6828442   0.31863403]
     [ 3.3995142   0.8315555 ]
     [ 2.952474    0.20283401]
     [ 3.9994783   1.9898007 ]
     [ 3.177472   -0.7077413 ]
     [ 4.6016474   1.2619112 ]
     [ 3.7589417   0.3846668 ]
     [ 3.4751458   0.9190201 ]
     [ 4.769388    0.8677293 ]
     [ 4.2582936   1.2986796 ]
     [ 2.3479323  -1.8858798 ]
     [ 2.7952015  -2.2166128 ]]
    [[ 3.4164658  -1.0052766 ]
     [ 1.9321456  -1.3281994 ]
     [ 2.0521107  -0.74952394]
     [ 1.6710792   0.1539567 ]
     [ 4.1430283   1.4800563 ]
     [ 2.0756607  -0.7332776 ]
     [ 3.4185765   0.44811672]
     [ 2.456689   -0.98729813]
     [ 2.2838135  -0.3245493 ]
     [ 2.8443294   0.49973762]
     [ 1.216873   -3.1501417 ]
     [ 3.8281333   0.55402565]
     [ 3.442759   -0.7065596 ]
     [ 2.284108   -0.4508926 ]
     [ 4.133273   -0.33166412]
     [ 3.0199373   0.2824789 ]
     [ 4.896252    1.0815585 ]
     [ 1.63007    -1.3738837 ]
     [ 2.7074492   0.1190974 ]
     [ 1.9657515   0.39840227]
     [ 0.7807703  -0.7797289 ]
     [ 3.5527487   0.03206369]
     [ 3.7547088   0.863721  ]
     [ 3.4966097  -0.8040037 ]
     [ 3.3478787   0.8097133 ]
     [ 1.9528145   0.0257263 ]
     [ 1.1911772  -2.1009395 ]
     [ 2.2039847  -1.1701142 ]
     [ 1.8008558  -0.9155716 ]
     [ 2.1968565  -0.6864447 ]
     [ 3.4441414   0.82855326]
     [ 1.9097906   0.16663043]
     [ 2.2970204   0.06629512]
     [ 3.4775705  -0.19815293]
     [ 3.436225   -0.9040807 ]
     [ 4.0168905   0.60799485]
     [ 4.622377    2.1399863 ]
     [ 3.5424714  -0.62062687]
     [ 3.8671942   0.72642076]
     [ 4.7557507   0.26398245]
     [ 3.3556087  -0.13284302]
     [ 2.2556136   1.5888209 ]
     [ 1.9901271  -1.5030661 ]
     [ 3.1888137  -1.1015378 ]
     [ 3.7112606   0.58437145]
     [ 1.873337   -1.3305986 ]
     [ 2.3305228  -0.78729934]
     [ 2.3786042  -0.20829356]
     [ 1.935495   -0.33023724]
     [ 2.8972607  -2.0022042 ]
     [ 2.3604558  -1.7830598 ]
     [ 3.4692235   0.7561949 ]
     [ 2.8129742  -0.16936752]
     [ 2.8613753   0.01127935]
     [ 3.5317512   0.55052567]
     [ 1.42588    -1.5491344 ]
     [ 3.2862704   0.8416566 ]
     [ 3.3947165   1.7853976 ]
     [ 2.3903952  -0.4342727 ]
     [ 2.7234092  -0.16278061]
     [ 2.6975718  -0.316723  ]
     [ 3.5991843   0.22209708]
     [ 1.4565184  -0.5807062 ]
     [ 0.23684587 -1.9213228 ]
     [ 3.8615997   1.299163  ]
     [ 2.7953117   1.1966505 ]
     [ 4.061893    1.7432718 ]
     [ 4.055545    1.4135718 ]
     [ 2.8269167  -0.8271987 ]
     [ 3.6067357  -0.8363072 ]
     [ 2.732785    0.35545978]
     [ 2.4373739   0.8067006 ]
     [ 3.001552    1.4490296 ]
     [ 3.8883998   0.5545169 ]
     [ 3.320626    1.316528  ]
     [ 5.036219    2.0972528 ]
     [ 3.154163   -0.58850425]
     [ 3.808474    0.5138567 ]
     [ 3.4862576   1.1768175 ]
     [ 3.2640505   0.34132737]
     [ 1.3654379  -1.1409143 ]
     [ 3.2269878  -0.1700801 ]
     [ 1.8900858  -0.5745691 ]
     [ 2.5908806  -0.58639365]
     [ 2.7386715   0.19503155]
     [ 3.00696     1.8081146 ]
     [ 3.4837737   0.64059275]
     [ 4.0794806   0.90478295]
     [ 3.21145    -0.44383317]
     [ 1.5717282  -2.1651392 ]
     [ 4.751172    1.7312646 ]
     [ 1.2234414  -1.8553522 ]
     [ 2.8209975   0.75291735]
     [ 3.6076052  -0.19393486]
     [ 2.3251011  -0.31116545]
     [ 2.8490512  -1.606772  ]
     [ 3.6846254  -0.5564069 ]
     [ 4.4700894   0.3335876 ]
     [ 3.234902    1.7519344 ]
     [ 1.8818238  -1.5031207 ]]
    [[ 4.659319    2.2228606 ]
     [ 2.9842722   1.2427484 ]
     [ 3.1889613   0.4323172 ]
     [ 1.4790623  -0.3691295 ]
     [ 1.67447    -1.2044528 ]
     [ 2.365844   -2.326474  ]
     [ 2.9608302  -0.22224419]
     [ 3.4079552   0.9065493 ]
     [ 2.7155309  -0.54401493]
     [ 1.3035811  -1.8794688 ]
     [ 4.784645   -0.48951426]
     [ 3.0400956  -0.2540687 ]
     [ 2.260685   -0.45106813]
     [ 2.0520945  -0.07182468]
     [ 3.2367997  -1.6020952 ]
     [ 2.963036    0.911781  ]
     [ 2.5931504  -0.6340022 ]
     [ 2.9595804  -0.16411008]
     [ 3.4972632   1.8706435 ]
     [ 4.914467    0.9414088 ]
     [ 5.4286413   1.4895277 ]
     [ 2.4889743  -1.1312754 ]
     [ 2.2340405  -0.25767633]
     [ 3.5153959   1.1222262 ]
     [ 1.9754169  -0.8217808 ]
     [ 2.9352698  -0.20705919]
     [ 1.6240423  -2.4857378 ]
     [ 3.3390565   0.87551063]
     [ 3.6463385   0.92372924]
     [ 4.4096847   0.26242855]
     [ 3.5251007   1.1343664 ]
     [ 3.2503805   1.02127   ]
     [ 3.2171805  -0.2600581 ]
     [ 2.8854442  -0.19846061]
     [ 3.865581    0.70418984]
     [ 2.4382534  -0.10544803]
     [ 3.6585515   1.0916463 ]
     [ 1.6281593  -0.7415812 ]
     [ 3.013763   -2.0950308 ]
     [ 3.199571    1.1802992 ]
     [ 4.3447514   1.7801094 ]
     [ 3.6369174   1.930476  ]
     [ 3.4582875  -0.05638097]
     [ 3.2617817  -0.09814701]
     [ 2.1526623  -1.9499648 ]
     [ 3.4918654  -0.293055  ]
     [ 2.725595   -0.47579554]
     [ 3.5589736   1.9283876 ]
     [ 4.543821    0.63101256]
     [ 2.6040611  -0.922605  ]
     [ 2.872703   -1.2290043 ]
     [ 2.0731995   0.8932303 ]
     [ 4.2025776   1.3156815 ]
     [ 3.2183645  -0.48917934]
     [ 3.0556707  -0.790309  ]
     [ 3.1705697  -0.05900618]
     [ 4.717359    0.6857529 ]
     [ 2.4476893  -1.3339119 ]
     [ 2.7202997   1.3718138 ]
     [ 3.337866    0.1755198 ]
     [ 2.6835778   0.21440122]
     [ 3.0723462  -1.1049789 ]
     [ 3.1879344  -0.07745412]
     [ 3.6488638  -1.4962895 ]
     [ 3.2978473   0.35763812]
     [ 2.4895177   0.04460227]
     [ 1.6839694  -0.52912045]
     [ 4.0270643   1.9605584 ]
     [ 3.1590102  -0.28565308]
     [ 2.815789    0.5577262 ]
     [ 0.43059143 -1.0456201 ]
     [ 4.704649    1.0227164 ]
     [ 5.1358643   0.937164  ]
     [ 3.6271174   0.10077359]
     [ 2.3911712  -0.67993826]
     [ 3.9000676  -0.43563882]
     [ 2.6139317  -0.95773196]
     [ 4.747201    0.12187828]
     [ 4.145006    0.13888437]
     [ 1.9132503  -1.3551538 ]
     [ 3.219288    1.2150623 ]
     [ 2.9951236   0.62067527]
     [ 2.152071    0.6124955 ]
     [ 3.0269299   0.3678101 ]
     [ 1.692473   -1.2761222 ]
     [ 4.137875   -1.7287518 ]
     [ 3.033157   -0.3846604 ]
     [ 3.607043    1.430188  ]
     [ 2.699407    0.28765982]
     [ 3.4955034   0.23586933]
     [ 2.604114    0.41850054]
     [ 2.7498336   0.43857077]
     [ 1.2301178  -1.2545457 ]
     [ 3.7376616   0.77137774]
     [ 1.9375368  -1.2136362 ]
     [ 2.6239278  -0.41546494]
     [ 3.0972774   1.0082943 ]
     [ 2.8057613  -1.3598387 ]
     [ 3.869319    1.3838311 ]
     [ 4.1566815   0.6542251 ]]
    [[ 3.65784335e+00 -1.15617716e+00]
     [ 3.34890771e+00  5.25234044e-01]
     [ 2.50147867e+00  2.41024420e-01]
     [ 2.67609262e+00  4.55673754e-01]
     [ 2.75850987e+00 -1.11545585e-01]
     [ 3.56545830e+00  1.56849599e+00]
     [ 3.79944873e+00 -1.68480009e-01]
     [ 3.55290484e+00 -7.17184007e-01]
     [ 3.73015904e+00 -9.16324437e-01]
     [ 3.87212944e+00  5.10860026e-01]
     [ 1.85248208e+00 -7.10401118e-01]
     [ 3.39051080e+00  1.38375485e+00]
     [ 3.77224016e+00  1.20666337e+00]
     [ 3.67724943e+00 -6.51603043e-01]
     [ 9.93822336e-01 -2.93519878e+00]
     [ 4.70002747e+00  1.37335384e+00]
     [ 3.47458863e+00 -6.22222900e-01]
     [ 3.59604311e+00  1.53548312e+00]
     [ 1.65769434e+00 -8.08632001e-02]
     [ 3.64727998e+00 -3.05378795e-01]
     [ 3.66670775e+00 -8.08904350e-01]
     [ 4.17906475e+00  2.02372789e+00]
     [ 2.58442664e+00 -7.41448104e-01]
     [ 1.30709875e+00 -3.70124668e-01]
     [ 2.66768289e+00  1.84735581e-01]
     [ 4.23212528e+00  1.77577996e+00]
     [ 7.26114035e-01 -9.53253746e-01]
     [ 2.64963603e+00  8.69782269e-01]
     [ 4.90333366e+00  1.92059249e-01]
     [ 1.77351367e+00  2.41015017e-01]
     [ 1.17723215e+00 -8.38671446e-01]
     [ 3.91509080e+00  2.52890438e-01]
     [ 3.79989100e+00  3.34209591e-01]
     [ 1.37057436e+00  2.95102835e-01]
     [ 3.39482069e+00  4.43154335e-01]
     [ 4.55553484e+00  1.36976612e+00]
     [ 5.42361212e+00  2.58011913e+00]
     [ 2.05377793e+00  3.23585689e-01]
     [ 3.23535538e+00 -1.04844904e+00]
     [ 3.41972733e+00 -7.90627360e-01]
     [ 2.45983791e+00 -1.62087405e+00]
     [ 2.16323352e+00  3.25936794e-01]
     [ 3.88449001e+00 -5.48125319e-02]
     [ 3.37692666e+00  1.03815925e+00]
     [ 4.05029297e+00 -7.92682469e-02]
     [ 2.37257051e+00  6.52706623e-01]
     [ 2.20609021e+00 -8.55651572e-02]
     [ 4.15389395e+00  1.05132747e+00]
     [ 3.29973006e+00  7.27460623e-01]
     [ 2.53652668e+00 -1.16928065e+00]
     [ 9.27395523e-01 -2.21444964e+00]
     [ 3.91757154e+00 -4.31477189e-01]
     [ 2.61060405e+00 -3.69411081e-01]
     [ 2.75803971e+00  1.51888713e-01]
     [ 3.19593239e+00 -3.61693203e-01]
     [ 2.57597065e+00  6.66353181e-02]
     [ 2.16787386e+00  4.14899826e-01]
     [ 2.04287791e+00  3.40312749e-01]
     [ 3.36451840e+00 -9.51587021e-01]
     [ 1.47765458e+00 -4.55978245e-01]
     [ 2.62914395e+00  5.23107722e-02]
     [ 3.82446337e+00 -1.38391685e-02]
     [ 3.96918130e+00  1.82499266e+00]
     [ 3.17576647e+00 -1.72761455e-01]
     [ 2.43898392e+00  8.97891641e-01]
     [ 2.47359443e+00 -2.20582652e+00]
     [ 2.48862457e+00 -1.61252904e+00]
     [ 3.35379505e+00 -5.84814370e-01]
     [ 3.19159675e+00  5.99879146e-01]
     [ 3.72664928e+00  4.17537242e-01]
     [ 9.45929766e-01 -9.89484608e-01]
     [ 2.83066726e+00  3.05290706e-03]
     [ 4.24330473e+00 -6.24085605e-01]
     [ 3.12932420e+00  3.95134181e-01]
     [ 3.30391121e+00 -1.59282625e-01]
     [ 2.27524900e+00 -3.02412421e-01]
     [ 2.81388211e+00 -2.81661606e+00]
     [ 3.75976348e+00  1.01407754e+00]
     [ 4.06535387e+00  1.87626445e+00]
     [ 4.27626991e+00  5.13682663e-01]
     [ 3.56209826e+00 -1.65804791e+00]
     [ 4.53080416e+00  4.28624690e-01]
     [ 1.20863652e+00 -1.63480425e+00]
     [ 4.18954802e+00  5.79400584e-02]
     [ 2.57598209e+00 -1.00264922e-02]
     [ 2.89495015e+00 -1.18340099e+00]
     [ 3.62865806e+00 -2.29935460e-02]
     [ 1.46596992e+00 -8.35801601e-01]
     [ 1.78301382e+00 -3.31987470e-01]
     [ 2.43328547e+00 -1.22102809e+00]
     [ 1.82216620e+00 -1.38414407e+00]
     [ 3.08558512e+00 -1.27807403e+00]
     [ 3.48472261e+00  7.30835378e-01]
     [ 3.04209352e+00  9.47762728e-01]
     [ 3.10171270e+00  4.00480956e-01]
     [ 3.84743285e+00  1.01566052e+00]
     [ 3.93324065e+00  5.75537503e-01]
     [ 3.65698719e+00 -6.18175566e-01]
     [ 4.32283211e+00  1.85527503e-01]
     [ 1.70770621e+00 -7.79599249e-01]]
    [[ 3.3192122e+00 -9.9553550e-03]
     [ 2.2628345e+00 -2.9421514e-02]
     [ 2.3285837e+00 -5.3672379e-01]
     [ 2.1618068e+00  7.2640657e-01]
     [ 2.8629715e+00  5.8260244e-01]
     [ 2.8535826e+00 -1.7171118e+00]
     [ 3.6345251e+00  7.1326154e-01]
     [ 5.1166382e+00  1.9811215e+00]
     [ 1.9561927e+00 -7.4551547e-01]
     [ 5.5018797e+00  5.8975506e-01]
     [ 2.5965233e+00 -5.4880077e-01]
     [ 1.3290128e+00 -1.9749202e+00]
     [ 3.7663012e+00  5.1004708e-01]
     [ 2.3944659e+00  1.8309551e-01]
     [ 2.7448590e+00 -3.9109412e-01]
     [ 3.1688609e+00  2.6408508e-01]
     [ 2.3717253e+00 -1.0132021e+00]
     [ 1.2509333e+00  4.1364872e-01]
     [ 3.5335398e+00 -4.4554606e-02]
     [ 2.9573708e+00  2.0840178e-01]
     [ 3.8954723e+00  1.6100194e+00]
     [ 2.4300749e+00  4.1975204e-02]
     [ 2.4954231e+00 -5.5328310e-01]
     [ 3.4533224e+00 -1.2794669e+00]
     [ 1.4032764e+00 -5.2996576e-01]
     [ 3.3889661e+00 -6.5956098e-01]
     [ 2.6157672e+00 -4.7674221e-01]
     [ 1.5315890e+00 -8.7161511e-02]
     [ 8.7027937e-01  3.0446249e-01]
     [ 2.9351680e+00  7.5099513e-02]
     [ 2.0237286e+00 -7.9153544e-01]
     [ 2.1193993e+00 -1.8718796e+00]
     [ 3.4560010e+00  4.6762565e-01]
     [ 2.1991189e+00 -6.8597198e-01]
     [ 3.8534973e+00  9.3705237e-01]
     [ 7.0094186e-01 -1.9696801e+00]
     [ 2.7380745e+00  6.5932173e-01]
     [ 4.0904341e+00  6.3293360e-02]
     [ 2.9352756e+00 -1.6463791e+00]
     [ 2.3787622e+00 -6.9418389e-01]
     [ 2.5914030e+00 -1.0896908e+00]
     [ 9.0417057e-01 -8.2356638e-01]
     [ 3.5796144e+00 -1.2434078e+00]
     [ 2.4560759e+00  1.0660412e-01]
     [ 6.5603715e-01 -8.5171394e-02]
     [ 4.2779117e+00  1.0496728e+00]
     [ 4.1130719e+00 -4.4892141e-01]
     [ 3.0799665e+00  1.2698636e+00]
     [ 3.8397741e+00  1.0449322e+00]
     [ 4.1238966e+00 -5.5811483e-01]
     [ 1.5959564e+00 -1.2860187e+00]
     [ 4.2476492e+00 -8.3088559e-01]
     [ 4.3471389e+00  1.0781559e+00]
     [ 1.5619017e+00  3.3748916e-01]
     [ 2.1048658e+00 -4.7861141e-01]
     [ 2.8568232e+00 -6.5457249e-01]
     [ 4.9740081e+00  3.9427403e-01]
     [ 3.0259199e+00  7.1045309e-01]
     [ 4.1179490e+00  1.8374345e+00]
     [ 2.1068153e+00 -6.1744201e-01]
     [ 2.4876020e+00 -1.3240035e-01]
     [ 4.2281795e+00  3.2677528e-01]
     [ 2.8540688e+00 -1.2777050e+00]
     [ 2.7971690e+00  5.1037389e-01]
     [ 2.8850048e+00  1.4948744e+00]
     [ 3.5427372e+00  5.3227621e-01]
     [ 3.5312135e+00 -5.8901739e-01]
     [ 3.5491800e+00 -1.0499653e+00]
     [ 3.9491107e+00 -8.3769298e-01]
     [ 3.1444502e+00 -5.6576067e-01]
     [ 2.4022913e+00  2.2441205e-01]
     [ 3.9652772e+00  1.6141484e+00]
     [ 1.0048441e+00 -8.4882218e-01]
     [ 2.3422837e+00  4.3320340e-01]
     [ 3.9427397e+00  4.7608408e-01]
     [ 3.8701620e+00  8.0272985e-01]
     [ 2.1087496e+00  8.4960169e-01]
     [ 4.4136777e+00  3.5948652e-01]
     [ 3.6588297e+00  1.3809075e+00]
     [ 3.2500079e+00  4.8435333e-01]
     [ 8.3741164e-01 -2.7864773e+00]
     [ 1.2629817e+00 -1.1311194e+00]
     [ 3.5992301e+00 -7.5701100e-01]
     [ 3.9759860e+00  1.2761492e+00]
     [ 3.9211936e+00  9.5804232e-01]
     [ 5.8716512e-01 -1.8161457e+00]
     [ 4.2010069e+00  1.2924312e+00]
     [ 3.2467587e+00 -9.2987567e-01]
     [ 2.6812410e+00  1.4108082e-03]
     [ 1.9898703e+00  1.5930369e-02]
     [ 4.8465419e+00  5.3388524e-01]
     [ 2.7460334e+00  3.1963220e-01]
     [ 3.8306193e+00 -4.7825910e-02]
     [ 2.8655360e+00 -1.4194834e+00]
     [ 2.8488429e+00 -1.1690135e+00]
     [ 1.6292987e+00 -8.2498407e-01]
     [ 3.1222405e+00  9.9824154e-01]
     [ 4.4044805e+00 -1.8861790e-01]
     [ 9.4060463e-01 -1.0323966e+00]
     [ 2.4441040e+00  1.7564859e+00]]
    [[ 3.975091    0.3977049 ]
     [ 2.24971     0.21695744]
     [ 1.0214248  -1.9510756 ]
     [ 3.0806844  -0.65128624]
     [ 4.619049    0.3069133 ]
     [ 3.8387544   1.6260012 ]
     [ 3.0999465   1.2189643 ]
     [ 3.6808615   0.97075427]
     [ 2.1693347  -0.91867965]
     [ 2.4777083   0.7266807 ]
     [ 6.038007    1.1097304 ]
     [ 4.6385674   0.7068637 ]
     [ 4.342242    1.496254  ]
     [ 3.4821677   0.20464402]
     [ 3.4326692  -0.64010286]
     [ 3.8910446   0.9258884 ]
     [ 4.637865    1.4909312 ]
     [ 2.7787085  -0.2805139 ]
     [ 4.1612678   0.1704916 ]
     [ 1.8218604  -1.8672386 ]
     [ 2.286638   -1.0552653 ]
     [ 2.948914   -0.0189127 ]
     [ 2.9038105  -1.7113763 ]
     [ 3.4996934  -0.468917  ]
     [ 5.0220284  -1.2119493 ]
     [ 2.7764766  -0.3420663 ]
     [ 2.7931612  -1.182259  ]
     [ 2.3927972  -0.43474644]
     [ 2.4708369  -0.62283474]
     [ 2.6799028   0.84845525]
     [ 3.5920105   0.84708804]
     [ 2.7290125  -1.267452  ]
     [ 2.4804592  -2.112424  ]
     [ 3.1495712   1.1752115 ]
     [ 3.6942165   1.7318625 ]
     [ 2.7759275   0.8891216 ]
     [ 4.3933463   2.518468  ]
     [ 4.672301    0.7525332 ]
     [ 3.5094638   0.6340863 ]
     [ 2.1064558  -0.32708317]
     [ 2.5402353  -0.0546538 ]
     [ 4.1289854   1.1132278 ]
     [ 3.9949334   1.3412504 ]
     [ 2.7613995  -1.8341073 ]
     [ 2.4958549   0.57333374]
     [ 0.7063842  -1.3830377 ]
     [ 3.5756016  -0.5410328 ]
     [ 1.878205    0.16742517]
     [ 2.26478    -0.51950794]
     [ 3.2312965  -0.5872947 ]
     [ 3.321795    0.2220591 ]
     [ 2.9956334   0.30659983]
     [ 3.8641572   1.27459   ]
     [ 2.4387097  -0.4881951 ]
     [ 1.2769365  -0.5019969 ]
     [ 4.5520487   0.54109704]
     [ 4.0967526   1.4939922 ]
     [ 4.314315    1.0964073 ]
     [ 2.4272242  -0.04388195]
     [ 3.6163733   0.94293654]
     [ 1.4069169  -0.50936514]
     [ 1.7898111  -1.9186866 ]
     [ 2.1622689  -1.0662944 ]
     [ 3.3004477   0.29513204]
     [ 4.5166183   1.087571  ]
     [ 3.308639   -0.68481344]
     [ 3.9470122   0.529523  ]
     [ 2.6262357   0.0527888 ]
     [ 2.3522456  -0.6523156 ]
     [ 4.336389    2.0389194 ]
     [ 4.279479    0.58587   ]
     [ 2.9802997   1.6429157 ]
     [ 2.4429123  -1.7525074 ]
     [ 4.6280284   0.25515774]
     [ 4.0344286   0.51516867]
     [ 3.305991   -0.10147086]
     [ 3.2919374  -0.75300044]
     [ 1.9835156   0.05080998]
     [ 3.970653   -0.4286655 ]
     [ 2.9567974   0.1843024 ]
     [ 3.1633542   0.21286166]
     [ 3.9840372   2.7277586 ]
     [ 2.07881     0.23523088]
     [ 3.6665974  -1.1630838 ]
     [ 2.3144913  -0.8016676 ]
     [ 3.1773503  -0.9153934 ]
     [ 3.7163446  -0.6424705 ]
     [ 1.972863    0.11365172]
     [ 2.537499   -0.99005294]
     [ 2.3976216  -1.575452  ]
     [ 2.970253   -0.44194144]
     [ 1.882697   -0.713845  ]
     [ 1.7068905  -0.13136731]
     [ 1.6189464  -1.1092764 ]
     [ 4.1194363   0.35047293]
     [ 2.7519672  -0.14070001]
     [ 3.186332    0.05400762]
     [ 2.0876706  -0.137469  ]
     [ 3.126008    0.63952905]
     [ 3.6376815  -0.05672705]]
    [[ 4.286953   -0.5423851 ]
     [ 2.643407   -0.703655  ]
     [ 2.0643365  -0.66833305]
     [ 2.5154705   1.8615192 ]
     [ 3.2845166  -0.5637422 ]
     [ 3.6984298   2.0191529 ]
     [ 3.3326137   0.44238147]
     [ 3.0362842   0.75302875]
     [ 6.4155974   1.2311692 ]
     [ 2.051586   -0.7759666 ]
     [ 3.847414   -0.7373721 ]
     [ 1.4385191  -1.1084329 ]
     [ 1.3218257  -1.0411083 ]
     [ 2.4730418  -0.34523955]
     [ 2.1463535  -0.52968323]
     [ 2.312018    1.277411  ]
     [ 3.2797415   0.04961285]
     [ 2.1824667  -1.064755  ]
     [ 1.6063604  -1.3758417 ]
     [ 2.1998858  -1.4157771 ]
     [ 3.9302084   0.07437238]
     [ 0.71667767 -0.650077  ]
     [ 3.897553   -0.16108488]
     [ 2.4428892   1.7800149 ]
     [ 3.3338175   0.18575385]
     [ 1.3396226  -0.09700017]
     [ 2.618187    0.2762821 ]
     [ 2.21624    -0.28674376]
     [ 3.8292508   0.80597144]
     [ 3.5263171   1.231253  ]
     [ 4.210255    0.46105888]
     [ 3.4678707  -0.89684707]
     [ 4.099795    0.9637593 ]
     [ 4.0376453   1.0018203 ]
     [ 4.5836687   0.27106014]
     [ 2.8463686   0.50560945]
     [ 1.8373927  -1.795748  ]
     [ 2.4656959  -0.3688105 ]
     [ 2.198128   -1.490941  ]
     [ 3.014608    1.0817873 ]
     [ 1.9374563   0.50239855]
     [ 3.22347    -0.49822286]
     [ 2.5890489  -1.4841046 ]
     [ 0.3786665  -1.4823993 ]
     [ 2.7764995   0.8549607 ]
     [ 3.6793568   1.2454957 ]
     [ 2.3260944  -0.14688106]
     [ 2.2851062   0.4324463 ]
     [ 4.445945   -0.20386598]
     [ 3.349682   -1.3250245 ]
     [ 2.4700243  -0.2613062 ]
     [ 2.7615855  -0.3969106 ]
     [ 4.4031157   0.69259936]
     [ 3.0827296  -1.0249608 ]
     [ 2.1890607  -0.8413094 ]
     [ 1.8821892  -0.5180322 ]
     [ 2.4995174   0.04470152]
     [ 1.8798823   0.9143032 ]
     [ 0.7911876  -0.83992773]
     [ 3.43122    -0.54596937]
     [ 2.8699472   0.06546665]
     [ 3.786475   -0.02572911]
     [ 4.2248774   0.7389702 ]
     [ 2.788894   -0.982902  ]
     [ 1.8671544  -2.903332  ]
     [ 2.9591835  -0.28642574]
     [ 2.7811282  -0.13566242]
     [ 3.325489   -0.23289168]
     [ 3.2557864   0.38612503]
     [ 2.6091766   0.0755619 ]
     [ 1.8648384  -0.65191346]
     [ 4.7387886  -0.20407265]
     [ 1.5858897  -0.9614171 ]
     [ 2.9600725  -0.591159  ]
     [ 4.402535    0.79858375]
     [ 2.790989   -1.2028537 ]
     [ 3.006522    0.9656683 ]
     [ 1.9558848   0.0333819 ]
     [ 3.6347373   0.19599095]
     [ 1.4529845  -0.0327688 ]
     [ 3.782046    1.4324702 ]
     [ 2.6558182  -0.9940763 ]
     [ 3.325879    0.44304386]
     [ 3.9812293   1.7031318 ]
     [ 3.6321836  -0.35724616]
     [ 2.7213666   0.5028726 ]
     [ 2.2154176   0.4342667 ]
     [ 1.0279144  -0.570507  ]
     [ 2.7042162   0.40572637]
     [ 1.8212585   0.9292338 ]
     [ 2.6903005   0.04581288]
     [ 3.665615    1.1076498 ]
     [ 1.1879448  -1.3300425 ]
     [ 3.748898    2.271745  ]
     [ 3.4029756   0.788164  ]
     [ 3.0867028   0.461472  ]
     [ 3.958189   -0.6047003 ]
     [ 3.759851   -0.2216666 ]
     [ 2.9644213   0.8899966 ]
     [ 2.4089108   0.20824279]]
    [[ 2.3886466e+00 -1.1758463e+00]
     [ 6.1804190e+00  1.4076213e+00]
     [ 2.9764211e+00  4.4391808e-01]
     [ 5.0639033e+00  1.5698258e+00]
     [ 3.5989447e+00 -1.6009636e-01]
     [ 4.1062717e+00 -5.0412452e-01]
     [ 2.7889421e+00 -4.3450791e-01]
     [ 3.3057153e+00 -4.2729914e-01]
     [ 2.3688321e+00 -9.0523434e-01]
     [ 2.9319382e+00  1.0951124e+00]
     [ 3.1620789e+00  1.0435702e+00]
     [ 1.5101058e+00 -4.1062576e-01]
     [ 2.2728527e+00  1.4858770e+00]
     [ 4.8003750e+00  1.3738242e-01]
     [ 1.4779764e+00 -4.0476623e-01]
     [ 3.4600365e+00 -1.7295101e+00]
     [ 4.2440534e+00  1.3682401e+00]
     [ 2.4151795e+00  5.4177028e-01]
     [ 3.7539551e+00  3.6521664e-01]
     [ 2.8706827e+00  1.9726771e-01]
     [ 2.2687044e+00 -1.8989731e-01]
     [ 3.3778570e+00  8.3935106e-01]
     [ 3.6911104e+00 -3.9498404e-02]
     [ 2.7438428e+00 -5.9215450e-01]
     [ 2.6858783e+00  5.4061985e-01]
     [ 4.3596749e+00 -2.8331435e-01]
     [ 1.2610573e+00  2.6104939e-01]
     [ 4.0915632e+00  1.1075131e+00]
     [ 4.2486687e+00  5.7529676e-01]
     [ 1.0024749e+00 -1.9843522e+00]
     [ 2.9415245e+00  8.9899457e-01]
     [ 2.5447521e+00 -8.1980936e-02]
     [ 2.5262141e+00  1.0818826e-03]
     [ 3.5917778e+00 -6.6603690e-01]
     [ 1.5311853e+00 -1.4641839e+00]
     [ 2.0432618e+00 -1.2440642e+00]
     [ 2.7166235e+00 -1.3037676e-01]
     [ 1.8996997e+00 -8.8258553e-01]
     [ 2.3128743e+00 -8.6461812e-01]
     [ 2.8338058e+00  1.5702401e-01]
     [ 3.1716988e+00  4.3492940e-01]
     [ 2.3686640e+00  6.2219429e-01]
     [ 4.7025447e+00  1.3979743e+00]
     [ 3.4946661e+00 -2.6429796e-01]
     [ 2.1541011e+00 -7.3292965e-01]
     [ 2.2833772e+00  3.2427311e-01]
     [ 4.7188129e+00  8.1169569e-01]
     [ 4.2808619e+00  6.0386077e-02]
     [ 3.3643174e+00  6.8215740e-01]
     [ 3.6955674e+00  2.1028202e+00]
     [ 1.1156207e+00  1.2839743e-01]
     [ 5.0516491e+00  1.5909698e+00]
     [ 2.6692486e+00  1.5272933e+00]
     [ 2.8862469e+00 -5.0059849e-01]
     [ 2.6388214e+00 -5.9750319e-01]
     [ 2.3906398e+00  7.6070142e-01]
     [ 3.8620822e+00  8.2422584e-01]
     [ 4.9977503e+00  1.1669680e+00]
     [ 3.4853151e+00 -1.2767669e+00]
     [ 3.1867356e+00 -3.4573141e-01]
     [ 2.3685005e+00  3.4338453e-01]
     [ 2.5593133e+00 -1.0033675e+00]
     [ 3.1506765e+00  1.4470063e+00]
     [ 3.7505851e+00 -4.3632442e-01]
     [ 2.6617146e+00 -4.7762769e-01]
     [ 2.0814729e+00 -4.7002232e-01]
     [ 2.1377344e+00 -1.1393352e+00]
     [ 3.1523013e+00 -2.6643845e-01]
     [ 4.8184390e+00  1.2795980e+00]
     [ 4.7836456e+00 -1.9815616e-01]
     [ 4.0583053e+00  2.1104975e+00]
     [ 3.9170678e+00  4.2029727e-01]
     [ 3.6306436e+00 -1.3666171e-01]
     [ 3.9668710e+00 -6.2749350e-01]
     [ 4.4649057e+00 -3.5314074e-01]
     [ 2.6428328e+00  1.2308358e+00]
     [ 3.7817113e+00  1.1251191e+00]
     [ 2.7941198e+00  1.1871889e+00]
     [ 2.9205184e+00  1.2215290e+00]
     [ 2.7620931e+00  4.6665776e-01]
     [ 2.6973283e+00 -1.5435223e-01]
     [ 3.0951526e+00 -1.0619811e-02]
     [ 3.7399926e+00  1.2478968e+00]
     [ 5.3547726e+00  9.2181271e-01]
     [ 3.1396554e+00  2.3340338e-01]
     [ 4.6326714e+00  4.4753161e-01]
     [ 3.0282245e+00  5.7374108e-01]
     [ 1.6148481e+00 -4.3684727e-01]
     [ 3.4702072e+00  2.8284824e-01]
     [ 2.8078551e+00  4.9590644e-01]
     [ 1.8492447e+00 -9.0814584e-01]
     [ 2.8965516e+00 -8.3767611e-01]
     [ 2.6840670e+00  1.7881206e+00]
     [ 2.3071973e+00 -5.5874610e-01]
     [ 3.8873718e+00 -1.5651859e-01]
     [ 3.2229428e+00  1.7145185e+00]
     [ 1.0195950e+00 -2.0907717e+00]
     [ 3.8487411e+00  1.1091505e+00]
     [ 2.2189257e+00 -7.2592151e-01]
     [ 3.8892989e+00  1.6094819e+00]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]
     [0.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]
    [[1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]]


**배치 사이즈 객체 반환을 위한 설정**

무작위 값으로 반환된 미니 배치 데이터셋을 훈련시키기 위해 사용합니다.

다음 훈련에서 `enumerate()`메서드를 통해 for문에 사용하기 위한 미니 배치 사이즈 범위를 설정합니다.



```python
batch_size_object = tf.data.Dataset.from_tensor_slices((inputs, targets))
batch_size_object = batch_size_object.shuffle(buffer_size=1024).batch(batch_size)
```

### 미니 배치 경사하강법을 적용한 모델 훈련

1. 반복 훈련을 위한 에포크 수를 지정한다.
2. 에포크 마다 미니 배치 훈련을 위한 데이터셋을 무작위로 섞는다.
3. 무작위로 섞인 데이터셋을 배치 사이즈 만큼 미니 배치 단위로 나눈다.
4. 배치 사이즈로 나뉜 미니 배치 데이터셋을 배치 사이즈 만큼 훈련한다.
5. 각 미니 배치 훈련마다 손실 값을 측정한다.
6. 미니 배치 훈련이 끝날 때 마다 예측 정확도를 측정한다.

위 사항을 순서대로 에포크 수 만큼 반복하도록 구현하였습니다.


```python
epochs = 2                 # epochs 수
data_length = len(inputs)   # 데이터셋의 깅리

for epoch in range(epochs):
    # 에포크가 바뀔 시 훈련 데이터 섞기
    shuffled = np.random.permutation(data_length)
    inputs_shuffled = inputs[shuffled]
    targets_shuffled = targets[shuffled]
    count_batch = 0
    
    print("에포크%d 시작" % (epoch+1,))
    print("-------------------------------")
    for first in range(0, data_length, batch_size):
        # 무작위로 섞은 inputs, targets를 미니 배치 사이즈 만큼 나눈다.
        inputs_mini_batch = inputs_shuffled[first:first+batch_size]   # 무작위로 섞인 inputs 미니 배치
        targets_mini_batch = targets_shuffled[first:first+batch_size] # 무작위로 섞인 targets 미니 배치
        metric(inputs_mini_batch, targets_mini_batch)                 # 훈련 도중 예측 정확도를 출력하기 위한 함수 실행

        # 미니 배치 데이터셋을 미니 배치 사이즈 만큼 반복하여 손실 값 추정
        for step, (inputs_mini_batch, targets_mini_batch) in enumerate(batch_size_object):
            loss = training_step(inputs_mini_batch, targets_mini_batch)

            # 각 배치 마다 손실 값 확인(모든 스탭마다 확인)
            if step % 10 == 0:
                print(f"미니 배치{count_batch+1}")
                print(f"손실 값: {loss:.4f}")
                print(f"예측 정확도: {metric(inputs_mini_batch, targets_mini_batch): .4f}\n")
            # 미니 배치 훈련이 끝날 때마다 예측 정확도 출력
        count_batch += 1
    print("-------------------------------")
    print(f"에포크{epoch+1} 손실 값: {loss:.4f}    예측 정확도: {metric(inputs_mini_batch, targets_mini_batch): .4f}")
    print("-------------------------------")
```

    에포크1 시작
    -------------------------------
    미니 배치1
    손실 값: 13.9522
    예측 정확도:  0.0600
    
    미니 배치1
    손실 값: 0.2381
    예측 정확도:  0.6400
    
    미니 배치2
    손실 값: 0.3431
    예측 정확도:  0.9400
    
    미니 배치2
    손실 값: 0.2141
    예측 정확도:  0.6900
    
    미니 배치3
    손실 값: 0.3117
    예측 정확도:  0.8900
    
    미니 배치3
    손실 값: 0.2370
    예측 정확도:  0.6200
    
    미니 배치4
    손실 값: 0.3606
    예측 정확도:  0.9800
    
    미니 배치4
    손실 값: 0.2509
    예측 정확도:  0.6400
    
    미니 배치5
    손실 값: 0.3927
    예측 정확도:  0.9500
    
    미니 배치5
    손실 값: 0.2362
    예측 정확도:  0.6200
    
    미니 배치6
    손실 값: 0.2656
    예측 정확도:  0.9100
    
    미니 배치6
    손실 값: 0.2599
    예측 정확도:  0.5400
    
    미니 배치7
    손실 값: 0.3214
    예측 정확도:  0.9200
    
    미니 배치7
    손실 값: 0.2336
    예측 정확도:  0.6300
    
    미니 배치8
    손실 값: 0.3189
    예측 정확도:  0.9300
    
    미니 배치8
    손실 값: 0.2476
    예측 정확도:  0.6500
    
    미니 배치9
    손실 값: 0.3728
    예측 정확도:  0.9800
    
    미니 배치9
    손실 값: 0.2360
    예측 정확도:  0.6200
    
    미니 배치10
    손실 값: 0.3936
    예측 정확도:  0.9100
    
    미니 배치10
    손실 값: 0.2272
    예측 정확도:  0.6500
    
    미니 배치11
    손실 값: 0.3386
    예측 정확도:  0.9400
    
    미니 배치11
    손실 값: 0.2517
    예측 정확도:  0.6000
    
    미니 배치12
    손실 값: 0.4202
    예측 정확도:  0.9300
    
    미니 배치12
    손실 값: 0.2247
    예측 정확도:  0.6600
    
    미니 배치13
    손실 값: 0.3637
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.2498
    예측 정확도:  0.5700
    
    미니 배치14
    손실 값: 0.5014
    예측 정확도:  0.9400
    
    미니 배치14
    손실 값: 0.2261
    예측 정확도:  0.6600
    
    미니 배치15
    손실 값: 0.4132
    예측 정확도:  0.9500
    
    미니 배치15
    손실 값: 0.2552
    예측 정확도:  0.6100
    
    미니 배치16
    손실 값: 0.3509
    예측 정확도:  0.9400
    
    미니 배치16
    손실 값: 0.2415
    예측 정확도:  0.6200
    
    미니 배치17
    손실 값: 0.3459
    예측 정확도:  0.9300
    
    미니 배치17
    손실 값: 0.2286
    예측 정확도:  0.6500
    
    미니 배치18
    손실 값: 0.4056
    예측 정확도:  0.9200
    
    미니 배치18
    손실 값: 0.2430
    예측 정확도:  0.5900
    
    미니 배치19
    손실 값: 0.4773
    예측 정확도:  0.9100
    
    미니 배치19
    손실 값: 0.2434
    예측 정확도:  0.5800
    
    미니 배치20
    손실 값: 0.3642
    예측 정확도:  0.9600
    
    미니 배치20
    손실 값: 0.2534
    예측 정확도:  0.5900
    
    -------------------------------
    에포크1 손실 값: 0.2418    예측 정확도:  0.5900
    -------------------------------
    에포크2 시작
    -------------------------------
    미니 배치1
    손실 값: 0.3334
    예측 정확도:  0.9200
    
    미니 배치1
    손실 값: 0.2261
    예측 정확도:  0.6600
    
    미니 배치2
    손실 값: 0.2716
    예측 정확도:  0.9400
    
    미니 배치2
    손실 값: 0.2363
    예측 정확도:  0.6200
    
    미니 배치3
    손실 값: 0.3369
    예측 정확도:  0.9500
    
    미니 배치3
    손실 값: 0.2017
    예측 정확도:  0.7200
    
    미니 배치4
    손실 값: 0.3328
    예측 정확도:  0.9500
    
    미니 배치4
    손실 값: 0.2419
    예측 정확도:  0.6700
    
    미니 배치5
    손실 값: 0.4074
    예측 정확도:  0.9400
    
    미니 배치5
    손실 값: 0.2237
    예측 정확도:  0.6700
    
    미니 배치6
    손실 값: 0.2900
    예측 정확도:  0.9300
    
    미니 배치6
    손실 값: 0.2532
    예측 정확도:  0.5900
    
    미니 배치7
    손실 값: 0.3504
    예측 정확도:  0.9800
    
    미니 배치7
    손실 값: 0.2222
    예측 정확도:  0.6900
    
    미니 배치8
    손실 값: 0.2983
    예측 정확도:  0.9600
    
    미니 배치8
    손실 값: 0.2362
    예측 정확도:  0.6200
    
    미니 배치9
    손실 값: 0.3280
    예측 정확도:  0.9600
    
    미니 배치9
    손실 값: 0.2219
    예측 정확도:  0.6700
    
    미니 배치10
    손실 값: 0.4173
    예측 정확도:  0.9300
    
    미니 배치10
    손실 값: 0.2381
    예측 정확도:  0.6100
    
    미니 배치11
    손실 값: 0.3233
    예측 정확도:  0.8900
    
    미니 배치11
    손실 값: 0.2193
    예측 정확도:  0.7300
    
    미니 배치12
    손실 값: 0.3858
    예측 정확도:  0.9400
    
    미니 배치12
    손실 값: 0.2470
    예측 정확도:  0.6000
    
    미니 배치13
    손실 값: 0.4092
    예측 정확도:  0.9300
    
    미니 배치13
    손실 값: 0.2223
    예측 정확도:  0.6700
    
    미니 배치14
    손실 값: 0.3000
    예측 정확도:  0.9100
    
    미니 배치14
    손실 값: 0.2301
    예측 정확도:  0.6400
    
    미니 배치15
    손실 값: 0.3969
    예측 정확도:  0.9200
    
    미니 배치15
    손실 값: 0.2292
    예측 정확도:  0.6300
    
    미니 배치16
    손실 값: 0.4497
    예측 정확도:  0.9500
    
    미니 배치16
    손실 값: 0.2298
    예측 정확도:  0.6500
    
    미니 배치17
    손실 값: 0.2779
    예측 정확도:  0.9600
    
    미니 배치17
    손실 값: 0.2004
    예측 정확도:  0.7300
    
    미니 배치18
    손실 값: 0.2703
    예측 정확도:  0.9200
    
    미니 배치18
    손실 값: 0.1100
    예측 정확도:  0.9000
    
    미니 배치19
    손실 값: 0.1755
    예측 정확도:  0.9000
    
    미니 배치19
    손실 값: 0.0481
    예측 정확도:  0.9400
    
    미니 배치20
    손실 값: 0.0963
    예측 정확도:  0.9400
    
    미니 배치20
    손실 값: 0.0459
    예측 정확도:  0.9600
    
    -------------------------------
    에포크2 손실 값: 0.0272    예측 정확도:  0.9700
    -------------------------------


미니배치 훈련을 2번 반복한 결과 초기 손실 값이 크게 나타났으나,

 점점 줄어들어 금방 안정화된 값을 얻을 수 있었습니다.

하지만 미니배치 훈련 과정에서 데이터셋이 무작위로 초기화된 후 다시 훈련 과정을 거치기 때문인지

예측 정확도는 불규칙하게 좋아졌다 나빠졌다 하는 것으로 나타납니다.

따라서 에포크 수를 증가시켜 10번 다시 반복 훈련을 실행해 보겠습니다.


```python
epochs = 10                 # epochs 수
data_length = len(inputs)   # 데이터셋의 깅리

for epoch in range(epochs):
    # 에포크가 바뀔 시 훈련 데이터 섞기
    shuffled = np.random.permutation(data_length)
    inputs_shuffled = inputs[shuffled]
    targets_shuffled = targets[shuffled]
    count_batch = 0
    
    print("에포크%d 시작" % (epoch+1,))
    print("-------------------------------")
    for first in range(0, data_length, batch_size):
        # 무작위로 섞은 inputs, targets를 미니 배치 사이즈 만큼 나눈다.
        inputs_mini_batch = inputs_shuffled[first:first+batch_size]   # 무작위로 섞인 inputs 미니 배치
        targets_mini_batch = targets_shuffled[first:first+batch_size] # 무작위로 섞인 targets 미니 배치
        metric(inputs_mini_batch, targets_mini_batch)                 # 훈련 도중 예측 정확도를 출력하기 위한 함수 실행

        # 미니 배치 데이터셋을 미니 배치 사이즈 만큼 반복하여 손실 값 추정
        for step, (inputs_mini_batch, targets_mini_batch) in enumerate(batch_size_object):
            loss = training_step(inputs_mini_batch, targets_mini_batch)

            # 각 배치 마다 손실 값 확인(모든 스탭마다 확인)
            if step % 10 == 0:
                print(f"미니 배치{count_batch+1}")
                print(f"손실 값: {loss:.4f}")
                print(f"예측 정확도: {metric(inputs_mini_batch, targets_mini_batch): .4f}\n")
            # 미니 배치 훈련이 끝날 때마다 예측 정확도 출력
        count_batch += 1
    print("-------------------------------")
    print(f"에포크{epoch+1} 손실 값: {loss:.4f}    예측 정확도: {metric(inputs_mini_batch, targets_mini_batch): .4f}")
    print("-------------------------------")
```

    에포크1 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0766
    예측 정확도:  0.9600
    
    미니 배치1
    손실 값: 0.0323
    예측 정확도:  0.9700
    
    미니 배치2
    손실 값: 0.0785
    예측 정확도:  0.9600
    
    미니 배치2
    손실 값: 0.0294
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0823
    예측 정확도:  0.9900
    
    미니 배치3
    손실 값: 0.0335
    예측 정확도:  0.9800
    
    미니 배치4
    손실 값: 0.0886
    예측 정확도:  0.8500
    
    미니 배치4
    손실 값: 0.0305
    예측 정확도:  0.9800
    
    미니 배치5
    손실 값: 0.0759
    예측 정확도:  0.9300
    
    미니 배치5
    손실 값: 0.0240
    예측 정확도:  0.9900
    
    미니 배치6
    손실 값: 0.0683
    예측 정확도:  0.9900
    
    미니 배치6
    손실 값: 0.0194
    예측 정확도:  0.9900
    
    미니 배치7
    손실 값: 0.0543
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0410
    예측 정확도:  0.9700
    
    미니 배치8
    손실 값: 0.0551
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0459
    예측 정확도:  0.9700
    
    미니 배치9
    손실 값: 0.0647
    예측 정확도:  0.9800
    
    미니 배치9
    손실 값: 0.0176
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0590
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0294
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0510
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0178
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0425
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0216
    예측 정확도:  0.9900
    
    미니 배치13
    손실 값: 0.0451
    예측 정확도:  0.9900
    
    미니 배치13
    손실 값: 0.0157
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0613
    예측 정확도:  0.9800
    
    미니 배치14
    손실 값: 0.0185
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0421
    예측 정확도:  0.9800
    
    미니 배치15
    손실 값: 0.0186
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0456
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0247
    예측 정확도:  0.9700
    
    미니 배치17
    손실 값: 0.0426
    예측 정확도:  0.9900
    
    미니 배치17
    손실 값: 0.0219
    예측 정확도:  0.9900
    
    미니 배치18
    손실 값: 0.0639
    예측 정확도:  0.9500
    
    미니 배치18
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0329
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0118
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0366
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0165
    예측 정확도:  1.0000
    
    -------------------------------
    에포크1 손실 값: 0.0148    예측 정확도:  1.0000
    -------------------------------
    에포크2 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0404
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0191
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0486
    예측 정확도:  0.9900
    
    미니 배치2
    손실 값: 0.0131
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0262
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0164
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0312
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0150
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0353
    예측 정확도:  0.9900
    
    미니 배치5
    손실 값: 0.0162
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0429
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0195
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0323
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0124
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0386
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0178
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0386
    예측 정확도:  0.9900
    
    미니 배치9
    손실 값: 0.0153
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0401
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0161
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0297
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0195
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0234
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0127
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0359
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0135
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0366
    예측 정확도:  0.9900
    
    미니 배치14
    손실 값: 0.0161
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0271
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0161
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0371
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0142
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0342
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0171
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0381
    예측 정확도:  0.9900
    
    미니 배치18
    손실 값: 0.0210
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0283
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0123
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0306
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0200
    예측 정확도:  0.9900
    
    -------------------------------
    에포크2 손실 값: 0.0155    예측 정확도:  1.0000
    -------------------------------
    에포크3 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0298
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0125
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0331
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0144
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0377
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0151
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0290
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0182
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0334
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0163
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0317
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0191
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0341
    예측 정확도:  0.9900
    
    미니 배치7
    손실 값: 0.0159
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0322
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0162
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0295
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0205
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0292
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0158
    예측 정확도:  0.9900
    
    미니 배치11
    손실 값: 0.0338
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0141
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0321
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0188
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0306
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0150
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0385
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0187
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0313
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0191
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0403
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0182
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0292
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0127
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0270
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0143
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0359
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0128
    예측 정확도:  0.9900
    
    미니 배치20
    손실 값: 0.0348
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0134
    예측 정확도:  1.0000
    
    -------------------------------
    에포크3 손실 값: 0.0148    예측 정확도:  1.0000
    -------------------------------
    에포크4 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0359
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0116
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0332
    예측 정확도:  0.9900
    
    미니 배치2
    손실 값: 0.0171
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0327
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0179
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0313
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0133
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0266
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0178
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0324
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0130
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0217
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0129
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0229
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0130
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0277
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0149
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0337
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0100
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0302
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0130
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0283
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0152
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0335
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0081
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0353
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0143
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0284
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0194
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0360
    예측 정확도:  0.9900
    
    미니 배치16
    손실 값: 0.0152
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0211
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0117
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0273
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0151
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0272
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0190
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0262
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0176
    예측 정확도:  1.0000
    
    -------------------------------
    에포크4 손실 값: 0.0153    예측 정확도:  1.0000
    -------------------------------
    에포크5 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0259
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0177
    예측 정확도:  0.9900
    
    미니 배치2
    손실 값: 0.0458
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0165
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0381
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0168
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0402
    예측 정확도:  0.9800
    
    미니 배치4
    손실 값: 0.0174
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0266
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0201
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0281
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0119
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0339
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0138
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0332
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0143
    예측 정확도:  0.9900
    
    미니 배치9
    손실 값: 0.0372
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0327
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0140
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0234
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0252
    예측 정확도:  0.9800
    
    미니 배치12
    손실 값: 0.0224
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0159
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0333
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0201
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0337
    예측 정확도:  0.9900
    
    미니 배치14
    손실 값: 0.0138
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0273
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0237
    예측 정확도:  0.9900
    
    미니 배치16
    손실 값: 0.0317
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0174
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0286
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0225
    예측 정확도:  0.9900
    
    미니 배치18
    손실 값: 0.0318
    예측 정확도:  0.9900
    
    미니 배치18
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0337
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0187
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0322
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0188
    예측 정확도:  1.0000
    
    -------------------------------
    에포크5 손실 값: 0.0168    예측 정확도:  1.0000
    -------------------------------
    에포크6 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0274
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0154
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0301
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0192
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0273
    예측 정확도:  0.9900
    
    미니 배치3
    손실 값: 0.0144
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0280
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0142
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0326
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0155
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0315
    예측 정확도:  0.9900
    
    미니 배치6
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0318
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0181
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0295
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0186
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0365
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0091
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0375
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0168
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0290
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0145
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0270
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0383
    예측 정확도:  0.9900
    
    미니 배치13
    손실 값: 0.0129
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0309
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0139
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0364
    예측 정확도:  0.9800
    
    미니 배치15
    손실 값: 0.0196
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0351
    예측 정확도:  0.9900
    
    미니 배치16
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0369
    예측 정확도:  0.9800
    
    미니 배치17
    손실 값: 0.0156
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0414
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0119
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0254
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0153
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0309
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0164
    예측 정확도:  1.0000
    
    -------------------------------
    에포크6 손실 값: 0.0111    예측 정확도:  1.0000
    -------------------------------
    에포크7 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0310
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0158
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0316
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0200
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0394
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0149
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0397
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0171
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0313
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0160
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0341
    예측 정확도:  0.9900
    
    미니 배치6
    손실 값: 0.0154
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0254
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0106
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0278
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0146
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0299
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0156
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0304
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0171
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0357
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0171
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0423
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0158
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0314
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0170
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0355
    예측 정확도:  0.9900
    
    미니 배치14
    손실 값: 0.0135
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0320
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0168
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0256
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0197
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0276
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0163
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0255
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0177
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0312
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0115
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0278
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0108
    예측 정확도:  1.0000
    
    -------------------------------
    에포크7 손실 값: 0.0187    예측 정확도:  0.9900
    -------------------------------
    에포크8 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0265
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0180
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0423
    예측 정확도:  0.9900
    
    미니 배치2
    손실 값: 0.0177
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0269
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0103
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0308
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0148
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0266
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0128
    예측 정확도:  0.9900
    
    미니 배치6
    손실 값: 0.0291
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0154
    예측 정확도:  0.9900
    
    미니 배치7
    손실 값: 0.0332
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0163
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0274
    예측 정확도:  0.9900
    
    미니 배치8
    손실 값: 0.0121
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0342
    예측 정확도:  0.9900
    
    미니 배치9
    손실 값: 0.0138
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0395
    예측 정확도:  0.9900
    
    미니 배치10
    손실 값: 0.0134
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0269
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0124
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0309
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0153
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0274
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0099
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0328
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0169
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0310
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0129
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0347
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0175
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0331
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0169
    예측 정확도:  0.9900
    
    미니 배치18
    손실 값: 0.0379
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0112
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0296
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0188
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0317
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0141
    예측 정확도:  1.0000
    
    -------------------------------
    에포크8 손실 값: 0.0176    예측 정확도:  1.0000
    -------------------------------
    에포크9 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0326
    예측 정확도:  1.0000
    
    미니 배치1
    손실 값: 0.0177
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0340
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0154
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0199
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0202
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0274
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0169
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0247
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0159
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0278
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0158
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0312
    예측 정확도:  0.9900
    
    미니 배치7
    손실 값: 0.0151
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0280
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0183
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0309
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0126
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0360
    예측 정확도:  0.9900
    
    미니 배치10
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0283
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0149
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0398
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0137
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0323
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0132
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0301
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0151
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0320
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0111
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0277
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0210
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0352
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0168
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0312
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0135
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0371
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0193
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0344
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0202
    예측 정확도:  0.9900
    
    -------------------------------
    에포크9 손실 값: 0.0155    예측 정확도:  1.0000
    -------------------------------
    에포크10 시작
    -------------------------------
    미니 배치1
    손실 값: 0.0278
    예측 정확도:  0.9900
    
    미니 배치1
    손실 값: 0.0133
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0305
    예측 정확도:  1.0000
    
    미니 배치2
    손실 값: 0.0160
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0316
    예측 정확도:  1.0000
    
    미니 배치3
    손실 값: 0.0177
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0315
    예측 정확도:  1.0000
    
    미니 배치4
    손실 값: 0.0142
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0351
    예측 정확도:  1.0000
    
    미니 배치5
    손실 값: 0.0175
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0257
    예측 정확도:  1.0000
    
    미니 배치6
    손실 값: 0.0193
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0281
    예측 정확도:  1.0000
    
    미니 배치7
    손실 값: 0.0146
    예측 정확도:  1.0000
    
    미니 배치8
    손실 값: 0.0327
    예측 정확도:  0.9900
    
    미니 배치8
    손실 값: 0.0163
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0323
    예측 정확도:  1.0000
    
    미니 배치9
    손실 값: 0.0180
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0217
    예측 정확도:  1.0000
    
    미니 배치10
    손실 값: 0.0153
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0261
    예측 정확도:  1.0000
    
    미니 배치11
    손실 값: 0.0116
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0355
    예측 정확도:  1.0000
    
    미니 배치12
    손실 값: 0.0169
    예측 정확도:  1.0000
    
    미니 배치13
    손실 값: 0.0348
    예측 정확도:  0.9900
    
    미니 배치13
    손실 값: 0.0175
    예측 정확도:  0.9900
    
    미니 배치14
    손실 값: 0.0298
    예측 정확도:  1.0000
    
    미니 배치14
    손실 값: 0.0164
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0268
    예측 정확도:  1.0000
    
    미니 배치15
    손실 값: 0.0165
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0307
    예측 정확도:  1.0000
    
    미니 배치16
    손실 값: 0.0165
    예측 정확도:  1.0000
    
    미니 배치17
    손실 값: 0.0363
    예측 정확도:  0.9900
    
    미니 배치17
    손실 값: 0.0190
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0280
    예측 정확도:  1.0000
    
    미니 배치18
    손실 값: 0.0133
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0307
    예측 정확도:  1.0000
    
    미니 배치19
    손실 값: 0.0147
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0309
    예측 정확도:  1.0000
    
    미니 배치20
    손실 값: 0.0114
    예측 정확도:  1.0000
    
    -------------------------------
    에포크10 손실 값: 0.0102    예측 정확도:  1.0000
    -------------------------------


에포크 수를 증가시킨 결과 예측 정확도가 매우 높은 수준으로 증가하게 되었습니다.

간혹 손실 값이 0.05에 근접하는 결과가 나타나기도 했으나, 에포크 수가 후반대로 진입하게 될수록 손실값 또한 매우 안정화된 수치로 반복하여 나타나는 것으로 타났습니다.

### 예측


```python
predictions = model(inputs)
```


```python
plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)
plt.show()
```



![output_51_0](https://user-images.githubusercontent.com/80394894/136712673-f284a38d-fd68-407d-a642-4ed1923657c4.png)




```python
metric(inputs, targets)
```




    0.998



### 결론
1. 일반적인 배치 훈련과는 다르게 미니배치 훈련은 훈련과정 속에서 무작위의 데이터를 갖도록 하기 때문에 손실 값 및 예측 정확도가 불규칙적으로 나타난다.

2. 하지만 거듭 훈련할 수록 손실 값은 줄어들고, 예측 정확도는 높아지는 것으로 보아 데이터셋은 모델에 적응하여 좋은 성능을 나타낸다.

3. 손실 값은 훈련 초기부터 금방 줄어드는 것으로 관측된다.

4. 반면에 예측 정확도는 훈련 초기에는 0.6 정도를 나타내며

   2번째 반복 훈련이 끝날 때 쯤에서야 0.9 정도의 성능을 나타내고 있다.(종종 0.8 밑으로 내려가기도 함)

5. 위 결과를 미루어볼 때 가장 효율적인 에포크 수는 3~4 정도로 예상한다.

#감사합니다.
