---
layout: post
title:  "[ML/DL] 머신러닝의 일반적인 작업 흐름"
toc: true
---

# 머신러닝의 일반적인 작업 흐름

- **기계 학습 문제를 정의하는 단계**
- **작업 모델 구현 단계**
- **생산 및 유지 관리하며 모델을 배포하는 단계**



기존 학습에는 레이블이 지정된 데이터 세트로 모델 훈련을 즉시 시작할 수 있다고 가정했으나,

실제로는 그렇지 않은 경우가 대부분이며, 데이터 세트가 아닌 해결하고자 할 문제를 통해 시작하는 것이 일반적입니다.

예를 들어,

1. "결혼식"을 검색하면, SNS에서 공유되는 결혼식 사진을 수동으로 태그를 달 필요 없이 검색할 수 있는 개인화된 이미지 검색 엔진.
2. 채팅 앱에서 스팸 또는 불쾌감을 주는 텍스트 컨텐츠를 표시.
3. 온라인 라디오 사용자를 위한 음악 추천 시스템 구현.
4. 전자상거래 웹 사이트에 대한 신용카드 사기 탐지.
5. 주어진 시간에 특정 사용자에게 어떤 광고를 제공할 것인지 결정하기 위한 광고 클릭률 예측.
6. 쿠키 제조 공정에서의 불량 쿠키 탐지.
7. 알려지지 않은 유적지 위치를 예측하기 위한 위성 사진 사용.

등의 예시가 있습니다. 



### 윤리적 고려사항

사람의 사진으로 누군가의 신뢰도를 평가하는 AI 프로젝트를 구현하고자 한다면, 이는 윤리적으로 문제가 될 가능성이 있습니다.

먼저, 프로젝트의 타당성에 문제가 발생하게 되는데, 누군가의 얼굴이 신뢰도와 연관하여 반영되는 명확한 근거가 존재하지 않습니다.

두 번째, 프로젝트에 대한 데이터 세트를 수집하는 과정에서 사진에 레이블을 붙이는 것은, 사람들의 편향된 시각과 편견을 기록하는 것과 같으므로 이러한 모든 과정에 대해서 윤리적인 문제가 발생하게 됩니다.

만약, AI 알고리즘이 특정 사람을 신뢰할 수 없다고 말하는 것은, 다른 사람이 신뢰할 수 없다고 말하는 것보다 더 큰 영향을 가지게 될 것으로 보입니다.

따라서, 기술은 결코 중립적일 수 없습니다. 만약 우리들의 연구가 세상에 영향을 미친다면, 도덕적인 방향을 가지게 될 것이며, 이는 기술적인 선택은 윤리적인 선택과 같습니다.





### 시작하기 전

머신 러닝의 보편적인 작업 흐름은 크게 세 가지로 구성됩니다.

1. **문제 정의** : 문제 해결 영역과 사용자 요구 사항을 기반으로 문제를 정의하는 단계입니다. 데이터 세트를 수집하고, 데이터가 무엇을 나타내는지 이해해야 하며, 작업의 성공을 측정하는 방법을 정의해야 합니다.
2. **모델 구현** : 머신러닝 모델이 처리할 수 있는 데이터를 준비하고, 모델의 평가 기준을 선택해야 합니다. 먼저, 과대적합이 될 수 있는 일반화 성능을 가진 모델을 훈련한 후, 최대한의 일반화 성능을 달성할 때 까지 모델을 조정하고 정규화 합니다.
3. **모델 배포** : 이해관계자에게 완성된 모델을 전달하고, 웹 서버 또는 모바일 앱, 웹 페이지, 임베디드 장치 등으로 모델을 적용합니다. 이후 실제 모델의 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집합니다.





## 1. 문제 정의

자신이 하고 있는 일의 맥락을 깊이 이해하지 않고서는 좋은 일을 할 수 없습니다.

따라서, 문제에 대하여 다음과 같은 물음에 대한 정의를 내려야 합니다.

고객이 문제를 해결하고자 하는 이유는 무엇인지?

문제의 해결책에서 어떤 가치를 얻을 수 있는지?

모델이 어떻게 사용될 것이며 고객의 업무 프로세스는 적합한지?

어떤 종류의 데이터가 사용 가능하거나 수집할 수 있는지?

어떤 종류의 머신러닝 모델을 업무에 적용할 수 있는지?



### 1.1 문제의 프레임 만들기

머신러닝 문제를 구체화하려면, 일반적으로 이해관계자들과의 많은 논의가 필요합니다.

다음과 같이 생각해야 할 질문들이 있습니다.



1. 입력 데이터는 무엇인가?, 무엇을 예측하려 하는가?

   훈련 데이터를 사용할 수 있는 경우에는 예측하는 방법을 배울 수 있습니다.

   예를 들어, 영화 리뷰와 영화에 대한 감정을 훈련 데이터로 사용할 수 있는 경우에만 영화 리뷰에 대한 감정을 분류하는 방법을 배울 수 있습니다.

   따라서, 일반적으로 이 단계에서 데이터 가용성에 대한 제한 요소를 다룹니다. 

   대부분의 경우 새로운 데이터 세트를 직접 수집하고 평가에 대한 평가를 입력해야 합니다.

2. 어떤 유형의 머신러닝 훈련 과제를 직면하고 있는가?(이항 분류, 다중 클래스 분류, 스칼라 회귀, 벡터 회귀, 다중 클래스 분류, 다중 레이블 분류, 이미지 분할, 순위, 군집화,  생성 모델, 강화 학습 등)

   하지만 특정 경우에는 위 방법이 머신러닝이 데이터를 이해하는 가장 좋은 방법이 아닐 수도 있고, 일반적인 통계 분석과 같은 다른 방법을 사용해야 할 수도 있습니다.

   - 이미지 검색 엔진 : 다중 클래스 분류, 다중 레이블 분류
   - 스팸 탐지 프로그 : 이진 분류 작업, 3-way 분류('공격적인 언어'라는 별도의 클래스 지정)
   - 음악 추천 프로그램 : 행렬 인수분해(협업 필터링) 
   - 신용 카드 사기 탐지 프로그램 : 이진 분류
   - 클릭률 예측 프로그램 : 스칼라 회귀
   - 불량 쿠키 탐지 : 객체 탐지 모델을 통한 이진 분류(이상 탐지 머신러닝 모델은 적합하지 않음)
   - 새로운 유적치 찾는 프로그램 : 이미지 유사도 순위 지정 알고리즘(알려진 유적지와 유사한 이미지 검색)

3. 기존의 문제해결 방법은 무엇인가?

   아마도 많은 사용자는 이미 스팸 필터링이나 신용카드 사기 탐지를 처리하는 알고리즘을 가지고 있을 것입니다.

   또는 쿠키 공장에서 이미 공정을 모니터링하고 불량 쿠키를 수동적으로 제거하거나, 특정 아티스트를 좋아하는 사용자에게 보낼 추천 곡의 재생 목록을 만드는 등의 과정을 사람이 직접 하고 있을 것입니다.

   따라서, 어떤 시스템이 이미 구축되어 있는지, 어떻게 작동하는지 등에 대하여 확실한 이해가 필요합니다.

4. 처리해야 할 특정 제약 조건이 있는가?

   예를 들어, 스팸 탐지 시스템을 구축하는 앱이 철저하게 종단 간 암호화가 되어있는 경우, 스팸 탐지 모델은 최종 사용자의 전화기에서 작동해야 하며 외부 데이터 세트에 대한 훈련을 받아야 합니다.

   불량 쿠키 탐지 모델의 경우, 원격 서버보다는 공장에서 임베디드 기기에서 실행되어야 하는 등의 지연 시간에 대한 제약이 있을 것입니다.

   이러한 경우를 대비하여 모델 적용을 위한 전체적인 맥락을 이해해야 합니다.



이후 입력과 타깃이 무엇인지, 문제에 적합한 머신러닝 알고리즘 등을 알아야 합니다.

또한, 머신러닝으로 모든 문제를 해결할 수 있는 것은 아니며, 입력 X와 타깃 Y의 예제를 종합했다고 해서

 X가 Y를 예측하기에 충분한 정보를 포함하고 있다고 볼 수 없습니다.

예를 들어, 주식 시장에서 최근 가격을 고려하여 주식의 움직임을 예측하려는 경우,

가격에 대한 많은 예측 정보가 포함되어 있지 않기 때문에 성공할 가능성이 매우 희박합니다.



### 1.2 데이터 세트 수집

작업의 특성을 이해하고 입력과 타깃이 무엇인지 알고 있다면 데이터 수집을 할 차례입니다.

대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 많은 비용이 드는 부분입니다.

- 이미지 검색 엔진 프로그램을 사용하려면, 분류할 레이블 세트를 선택해야 합니다.

  10,000개의 일반 이미지 카테고리로 정한 이후, 이 세트의 레이블을 사용하여 과거의 사용자가 업로드한

  수십만 개의 이미지에 수동적으로 태그를 지정해 주어야 합니다.

- 채팅 앱의 스팸 탐지 프로젝트의 경우 사용자 채팅이 종단 간 암호화되기 때문에, 해당 콘텐츠를 모델 학습에 사용할 수 없습니다.

  따라서, 수만 개의 공개 SNS 게시물로 구성된 별도의 데이터 세트에 액세스하고 수동으로 스팸, 공격적인 언어 또는 허용 가능한 태그들을 지정해야 합니다.

- 음악 추천 프로그램의 경우 사용자의 '좋아요' 데이터만을 사용할 수 있습니다. 따라서 새로운 데이터를 수집할 필요가 없습니다.

  클릭률 예측 프로그램 경우에도 과거 광고에 대한 광범위한 클릭률 기록을 사용합니다.

- 불량 쿠키 탐지의 경우 컨베이어 벨트 위에 카메라를 설치하여 수만 개의 이미지를 수집해야 하며, 이러한 이미지에 수동으로 레이블을 지정해야 합니다.

  불량 쿠키를 구별할 줄 아는 사람들은 쿠키 공장에서 일하는 사람들이므로 그들을 통해 레이블을 지정해야 합니다.

- 위성을 통한 새로운 유적지 탐지 프로젝트의 경우 고고학자 팀이 기존 관심 사이트의 데이터베이스를 수집해야 하며, 각 사이트에 대해 서로 다른 조건의 날씨에 촬영한 위성 이미지를 수집해야 합니다.

  좋은 모델을 얻기 위해서는 수천 개의 서로 다른 사이트를 통해 수집해야 합니다.



모델의 일반화 능력은 데이터의 수, 레이블의 신뢰성, 기능의 품질과 같은 훈련된 데이터의 속성에서 나오며,

좋은 데이터 세트는 관심과 투자의 가치가 있는 자산입니다.

따라서,  프로젝트에 추가적인 시간 투자를 할 수 있는 경우 가장 효과적인 방법은 모델을 점진적으로 개선 사항을 찾는 것보다 더 많은 데이터를 수집하는 것입니다.

알고리즘보다 데이터가 더 중요하다는 것은 2009년 구글의 연구원의 "The Unreasonable Effectiveness of Data" 논문에서 볼 수 있듯이 데이터의 중요성은 더욱 커지고 있습니다.



**데이터 레이블에 작성할 주석**

지도 학습을 수행하는 경우 이미지와 같은 입력을 수집하면 해당 입력에 대한 이미지의 태그와 같은 주석이 필요합니다.

여기서 이미지 태그는 예측을 위한 모델이 훈련할 대상입니다.

데이터 주석 프로세스는 대상의 품질을 결정하고 결과적으로 모델의 품질을 결정합니다.

1. 데이터에 직접 주석을 달아야 하는가?
2. 클라우드 소싱 플랫폼을 사용하여 레이블을 수집해야 하는가?
3. 전문 데이터 라벨링 회사의 서비스를 사용해야 하는가?

따라서 위와 같은 사용 가능한 옵션을 신중하게 고려해야 합니다.



최상의 옵션을 선택하기 위한 제약 조건은 다음과 같습니다.

1. 데이터 레이블 지정자는 전문가여야 하는지, 누구나 지정할 수 있는지 고려한다.
2. 만약 전문 지식이 필요하다면, 다른 사람들에게 쉽게 교육할 수 있는지 알아본다.
3. 그렇지 않다면, 전문가가 주석을 작성하는 방식을 이해하고 있는지 판단한다.

만약 내부에서 데이터 레이블을 지정하기로 결정했다면, 주석을 기록하는 데 어떤 소프트웨어를 사용할 것인지 고려해야 합니다.

또는, 해당 소프트웨어를 직접 개발해야 할 수도 있습니다. 이는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있습니다.



**대표성이 없는 데이터에 주의**

머신러닝의 학습 모델은 유사한 입력 데이터만을 이해할 수 있으므로, 훈련에 사용되는 데이터는 대표성이 있어야 합니다.

따라서, 가능하면 모델이 사용될 환경에서 직접 데이터를 수집해야 합니다.

만약, 수집한 데이터에 대한 훈련이 가능하지 않다면, 훈련 데이터와 제품 데이터가 어떻게 다른지 이해하고

차이를 적극적으로 수정해야 합니다.



이러한 문제는 개념 드리프트(Concept drift)에 대해 알고 있어야 하는 관련 현상입니다.

사용자 생성 데이터를 다루는 문제에서 개념 드리프트가 발생하게 되는데, 개념 드리프트는 생산 데이터의 속성이

시간이 지남에 따라 변경되어 모델 정확도가 점차 저하될 때 발생합니다.

음악 추천 모델을 예로, 과거에 훈련된 음악 추천 프로그램이 오늘날에는 효과적이지 않게 되는 것과 같습니다.

개념 드리프트는 사기 패턴이 거의 매일 바뀌는 신용 카드 사기 탐지와 같은 상황에서는 특히 심각할 수 있으며,

빠른 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재훈련이 필요합니다.



따라서, 머신러닝은 훈련 데이터에 있는 패턴을 기억하는 데만 사용할 수 있다는 점을 기억해야 합니다.

과거 데이터에 대해 훈련된 머신 러닝을 사용하여 미래를 예측하는 것은 미래가 과거처럼 행동할 것이라고 예측하는 것과 같습니다.



**샘플링 편향(Sampling bias)**

대표성이 없는 데이터의 일반적인 경우로 샘플링 편향이 있습니다. 

샘플링 편향은 데이터 수집 프로세스가 예측하려는 대상과

상호 작용하여 편향된 측정 결과가 발생하는 것을 뜻합니다.





### 1.3 데이터의 이해

모델 학습을 시작하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고,

기능 정보를 제공하고 잠재적인 문제를 선별해야 합니다.

- 데이터에 이미지나 자연어 텍스트가 포함된 경우 몇 가지 샘플을 직접 살펴봐야 합니다.
- 데이터의 수치적 특성이 포함된 경우 특성 값의 히스토그램을 그려 값의 범위와 다른 값의 빈도를 파악해야 합니다.
- 데이터에 위치 정보가 포함된 경우 지도에 표시하여 명확한 패턴이 나타나는지 판단합니다.
- 일부 샘플에서 기능이나 값이 누락되었는지 판단하고, 데이터를 준비할 때 누락된 데이터 문제를 처리해야 합니다.
- 작업이 분류 모델일 경우 데이터에 있는 각 클래스의 인스턴스 수를 파악합니다. 클래스가 동등하지 않을 경우 불균형에 대해 설명해야 합니다.
- 타겟 유출 확인 : 제품에서 사용할 수 없는 대상에 대한 정보를 제공하는 기능이 있는지 확인해야 합니다.





### 1.4 성공의 기준 선택

정확성, 정밀도와 재현율 등 성공을 위한 지표는 프로젝트 전반에 걸쳐 모든 기술적 선택 지침이 됩니다.



모든 클래스가 동일할 가능성이 있는 균형 클래스 분류의 경우 정확도와 수신자 조작 특성(ROC AUC) 영역이 일반적인 지표입니다.

클래스 불균형 문제, 순위 문제 또는 다중 레이블 분류의 경우 정확도와 ROC AUC의 가중치 형식뿐만 아니라 정밀도 및 재현율을 사용할 수 있습니다.

또한, 성공을 측정하는 데 사용할 사용자 지정 매트릭을 정의해야 하는 경우가 많습니다.





## 2. 모델 구현

진행 상황을 어떻게 측정할 것인지 알고 나면 모델 개발을 시작할 수 있습니다.



### 2.1 데이터 준비

딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않습니다. 

데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 하며 벡터화, 정규화, 결측치 처리가 포함됩니다.

참고 : 데이터 전처리 기술은 도메인(텍스트 또는 이미지 데이터)마다 다릅니다.



**벡터화(Vectorization)**

신경망의 모든 입력과 타깃은 일반적으로 부동 소수점 데이터의 텐서여야 합니다.

사운드, 이미지, 텍스트들을 처리하는 데 필요한 데이터가 무엇이든 먼저 데이터 벡터화 단계를 통해 텐서로 변환해야 합니다.

예를 들어, 리스트 형태의 정수 데이터를 원-핫 인코딩을 사용하여 데이터 텐서로 변환하는 방법이 있습니다.



**값 정규화(Value normalization)**

값 정규화는 예를 들어서 쉽게 설명할 수 있는데, MNIST 데이터를 분류할 때, 0~255 범위의 정수 데이터를

전처리 과정을 통해 부동 소수 `float32`로 변환하고 255로 나누어 0~1 범위의 값을 가지도록 정규화 하는 것입니다.

일반적으로 상대적으로 큰 값을 취하는 데이터 또는 이질적인 데이터를 신경망에 사용하는 것은 안전하지 않습니다.

만약 사용하게 되면, 대규모 그레이디언트 업데이트가 발생하여 네트워크가 원활하지 않을 수 있습니다.

네트워크 상에서 쉽게 학습하기 위해서는 다음과 같은 특성이 있어야 합니다.

1. 작은 값 사용 : 대부분의 값은 0~1 범위의 값으로 사용해야 한다.
2. 균일성 : 대부분의 특성이 동일한 범위의 값을 가져야 한다.



추가적으로, 다음과 같은 엄격한 정규화 방식을 사용하기도 합니다.

1. 평균이 0이 되도록 각 기능을 독립적으로 정규화한다.
2. 표준 편차가 1이 되도록 각 기능을 독립적으로 정규화한다.

이 방법은 NumPy 배열을 통해 쉽게 수행할 수 있습니다.



**누락된 값 처리(Handling missing values)**

가끔 데이터에 누락된 값이 발생할 수 있습니다. 이러한 경우, 해당 특성을 모든 샘플에 사용이 어려워지며,

훈련 또는 테스트 데이터에 누락된 값이 발생할 수 있습니다.

이러한 경우를 대비하여

- 기능이 범주형인 경우 :  누락된 값을 의미하는 새로운 범주를 생성하는 것이 안전합니다.

  모델은 타깃과 관련하여 누락된 값의 의미를 자동으로 학습이 가능해집니다.

- 특성이 숫자인 경우 : 0과 같은 임의의 값을 입력하지 말아야 합니다. 특성에 의해 형성된 잠재 공간에 불연속성이 생성되어 훈련된 모델이 일반화하기 더 어려워질 수 있습니다.

  누락된 값을 데이터 세트의 기능에 대한 평균 또는 중앙값으로 바꾸어 특성 값을 예측하도록 모델을 훈련시킬 수 있습니다.



테스트 데이터에서 누락된 범주 기능이 예상되지만 누락된 값이 없는 데이터에 대해 네트워크가 훈련된 경우,

네트워크는 누락된 값을 무시하는 방법을 훈련하지 않습니다. 따라서 누락된 항목이 있는 훈련 샘플을 인위적으로 생성해야 합니다.

일부 훈련 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부를 삭제해야 합니다.



### 2.2 평가 프로토콜 선택

모델의 목적은 일반화를 달성하는 것입니다. 모델 개발 프로세스 전반에 걸쳐 내리는 모든 모델링 결정은

일반화 성능을 측정하려는 검증 메트릭에 따라 결정됩니다.

검증 프로토콜의 목표는 실제 생산 데이터에서 선택한 성공 메트릭을 정확하게 추정하는 것입니다.

이 프로세스의 신뢰성은 유용한 모델을 구축하는데 중요합니다.



평가 프로토콜을 검토하는 세 가지 방법

1. Hold-out 검증 세트 유지 : 데이터가 많을 때 사용하는 방법
2. K-fold 교차 검증 수행 : 신뢰할 수 있는 홀드아웃 검증을 위한 샘플이 너무 적은 경우 사용
3. 반복적으로 k-fold 교차 검증 수행 : 사용 가능한 데이터가 거의 없을 때 매우 정확한 모델 평가 수행

위 방법 중 한 가지만 선택하여 사용해야 하며, 대부분의 경우 첫 번째만 사용해도 잘 작동합니다.

또한, 검증 세트의 대표성을 염두에 두고 훈련 세트와 검증 세트 사이에 중복 샘플이 없도록 주의해야 합니다.



### 2.3 기준선 돌파

모델에 대한 작업을 시작할 때의 초기 목표는 통계적 검정 능력을  달성하는 것입니다.

이는 즉, 단순한 기준선을 능가할 수 있는 작은 모델을 개발하는 것입니다.

다음은 기준선 돌파를 위한 가장 중요한 세 가지 사항입니다.

1. 기능 엔지니어링(Feature engineering) : 정보를 제공하지 않는 기능을 필터링하고 문제에 대한 지식을

   활용하여 유용하게 사용할 수 있는 새로운 기능을 개발할 수 있도록 한다.

2. 올바른 아키텍처 선택 : 사용할 모델 아키텍처의 유형, 네트워크, 적합성 등을 판단한다.

3. 충분히 좋은 훈련 구성 선택 : 손실 함수, 배치 크기, 학습률 조정을 통한 좋은 훈련 구성을 한다.



**참고 : 올바른 손실 함수 선택을 위한 표**

![1](C:\Users\tjdgh\Desktop\1.PNG)

문제 유형 - 마지막 층(Layer) 활성 함수 - 손실 함수

이진 분류 - 시그모이드 - binary_crossentropy

다중 클래스, 레이블 분류 - 소프트맥스 - categorical_crossentropy

다중 클래스, 다중 레이블 분류 - 시그모이드 - binary_crossentropy

임의의 값으로의 회귀 - 없음 - 평균 제곱 오차(MSE)



대부분의 문제에 대해 시작할 수 있는 기존 템플릿이 있습니다.

작업에서 가장 잘 수행할 가능성이 높은 기능 엔지니어링 기술 및 모델 아키텍처를 식별하기 위해

조사해야 할 선행 기술이 있습니다.

통계적 검정 능력을 달성하는 것이 항상 가능한 것은 아니며, 여러 합리적인 아키텍처를 시도한 후에도 간단한

기준선을 이길 수 없는 경우에는 다음과 같이 시도할 수 있습니다.

1. 입력이 주어지면 출력을 예측할 수 있다고 가정한다.
2. 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하기에 충분히 유익하다고 가정한다.

하지만, 이러한 가정은 거짓일 수 있으며, 처음부터 다시 시작해야 할 수도 있습니다.



### 2.4 확장 : 과대적합되는 모델 개발

통계적 검정 능력이 있는 모델을 얻은 후에는 해당 모델이 강력한지 판단해야 하며, 문제를 적절하게 모델링 하기에 충분한 층(Layer)과 매개변수가 있는지 확인해야 합니다.

가장 이상적인 모델은 과소적합과 과대적합의 경계에 있는 모델로, 이 경계가 어디에 있는지 알아내려면 먼저 경계를 넘어 과대적합 되어야 합니다.

모델이 과대적합될 경우, 얼마나 큰 모델이 필요한지 파악할 수 있습니다.

과대적합되는 모델 개발하는 세 가지 방법

1. 층(Layer)를 추가한다.
2. 층(Layer)를 기존보다 더 크게 만든다.
3. 더 많은 에포크 수의 훈련을 수행한다.

또한, 훈련 손실 및 검증 손실은 물론 지표에 대한 훈련 및 검증 값을 항상 모니터링해야 하며,

검증 데이터에 대한 모델의 성능 저하가 시작하는 시점부터 과대적합입니다.



### 2.5 모델 정규화 및 조정

통계적 검정 능력을 달성하고 과대적합할 수 있게 모델을 구성하면, 올바른 길을 가고 있는 것입니다.

이후부터는 일반화 성능을 최대화하는 것이 목표입니다.

일반화 성능을 최대화하는 것은 가장 많은 시간이 소요되며, 모델을 반복적으로 수정 및 훈련을 수행하며,

검증 데이터를 평가하는 일을 모델의 성능이 좋아질 때까지 반복해야 합니다.

또한, 시도해야 할 몇 가지 사항이 존재합니다.

1. 다른 아키텍처를 시도한다.
2. 층(Layer)를 추가하거나 제거한다.
3. 모델이 작은 경우 L1 또는 L2 정규화를 수행한다.
4. 최적의 구성을 찾기 위해 하이퍼파라미터를 조정한다.
5. 선택적으로 데이터 큐레이션 또는 기능 엔지니어링을 반복한다.
6. 더 나은 기능을 개발하거나, 유익하지 않은 기능을 제거한다.



KerasTuner와 같은 자동화된 하이퍼파라미터 조정 소프트웨어를 사용하여 모델 정규화 및 조정 작업의 많은

부분을 자동화할 수 있습니다.



하지만 검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모델에 노출됩니다.

이를 많은 반복을  통해 체계적으로 수행하면 결국 모델은 유효성 검사 프로세스에 과대적합됩니다.

이는 평가 프로세스의 신뢰성이 떨어질 수 있습니다.



만족스러운 모델을 개발하면 사용 가능한 모든 데이터에 대해 최종 모델을 교육하고 테스트 세트에서 마지막으로 평가할 수 있습니다.

테스트 세트의 성능이 유효성 검사 데이터에서 측정된 성능보다 훨씬 더 나쁘다는 것이 밝혀지면, 유효성 검사 절차가

결국 신뢰할 수 없거나 매개 변수를 조정하는 동안 유효성 검사 데이터에 과대적합이 되었음을 의미합니다.

이러한 모델의 경우 더 안정적인 평가 프로토콜로 전환하는 방법이 있습니다.(반복적인 K-fold 검증)





## 3. 모델 배포

모델이 테스트 세트에 대한 최종 평가를 성공적으로 통과했다면, 생산적인 일을 하며 배포할 준비가 되었습니다.



### 3.1 이해 관계자에게 작업을 설명하고 기대치 설정을 합니다.

성공과 고객의 신뢰는 사람들의 기대치를 지속적으로 충족하거나 초과하는 것을 뜻합니다.

실제 시스템에서는 예상의 절반에 그치지 못하며, 나머지 절반은 출시 전에 적절한 기대치를 설정할 수 있습니다.



또한, AI 시스템에 대한 비전문가의 기대가 종종 비현실적일 수 있습니다.

예를 들어, 그들은 시스템이 작업을 이해하고 작업의 맥락에서 인간과 같은 지식을 행사할 수 있다고 기대하는 경우가 있습니다.

이러한 문제를 해결하기 위해서는 실패에 대한 몇 가지 예를 보여주는 것을 고려해야 합니다.



특히, 이전에 사람이 처리하던 프로세스의 경우 사람 수준의 성능을 기대할 수도 있습니다.

하지만 대부분의 머신러닝 모델은 인간이 생성한 레이블을 근사하도록 훈련되었기 때문에 모델 성능의 기대치를 명확하게 전달해야 합니다.

또한, 모델의 성능 예측치를 비즈니스 목표와 명확하게 연관시켜야 합니다.



이해관계자와 주요 시작 매개변수의 선택에 대한 논의도 해야 합니다.

트랜잭션에 플래그를 지정해야 하는 확률 임계값과 같은 예가 있습니다.



### 3.2 추론 모델 제공

머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 Colab 노트북에 도착해도 끝나지 않습니다.

또한, 교육 중에 조작한 것과 동일한 파이썬 모델 객체를 생산에 투입하는 경우는 거의 없습니다.



먼저, 파이썬이 아닌 다른 언어의 모델을 내보내는 것이 좋습니다.

- 생산 환경은 파이썬을 전혀 지원하지 않을 수 있습니다.(모바일, 임베디드 시스템 등)
- 앱이 파이썬이 아닌 경우에 파이썬을 사용한 모델을 제공하면 상당한 오버헤드가 발생할 수 있습니다.



두 번째로, 생산 모델은 학습이 아니라 출력 예측에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을

줄일 수 있는 다양한 최적화를 수행할 필요가 있습니다.



**모델을 REST API로 사용**

모델을 제품으로 전환하는 일반적인 방법 중 하나로, 서버 또는 클라우드 인스턴스에 TensorFlow를 설치하고

REST API를 통해 모델의 예측을 쿼리 하는 것입니다. Flask 또는 TensorFlow Serving이라는 API로 모델을 제공

하기 위해 TensorFlow의 자체 라이브러리를 사용합니다.

TensorFlow Serving을 사용하면 Keras 모델을 빠르게 배포할 수 있습니다.



다음은 REST API를 사용할 경우 배포 설정입니다.

- 모델의 예측을 사용하는 응용 프로그램은 인터넷에 안정적으로 액세스할 수 있어야 합니다.

  애플리케이션이 모바일 앱인 경우, 원격 API에서 예측을 제공한다는 것은 애플리케이션을 비행기 모드나

  연결성이 낮은 환경에서 사용할 수 없다는 것을 의미합니다.

- 애플리케이션에는 엄격한 대기 시간을 요구하지 않아야 합니다.

  요청, 추론 및 응답 통신에는 일반적으로 약 500ms가 소요됩니다.

- 추론을 위해 전송된 입력 데이터는 매우 민감하지 않아도 됩니다.

  데이터는 모델에서 볼 수 있어야 하므로 서버에서 암호 해독된 형식으로 사용할 수 있어야 합니다.(HTTP 요청 및 응답)



이미지 검색 엔진 프로그램, 음악 추천 시스템, 신용 카드 사기 탐지 프로그램, 위성 이미지 프로그램은 REST API를 통해 제공하기에 적합합니다

모델을 REST API로 배포할 때 중요한 것은 코드를 자체적으로 호스팅 할 것인지, 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할 것인지를 결정해야 합니다.



만약, 구글 제품의 클라우드 플랫폼을 사용하면, TensorFlow 모델을 구글 클라우드 스토리지에 간단히 업로드하고

쿼리 할 수 있는 API 엔드 포인트를 제공할 수 있습니다.

예측 일괄 처리, 로드 밸런싱 및 스케일링과 같은 많은 실용적인 세부 사항을 처리할 수 있습니다.



**기기에 모델 적용**

스마트폰, 로봇, 임베디드 ARM CPU, 마이크로컨트롤러 등 해당 애플리케이션을 실행하는 동일한 기기에서 모델을 사용해야 할 수도 있습니다.

예를 들어, 휴대폰 카메라에서 사용하는 얼굴인식과 같은 모델을 뜻합니다.



다음은 기기에 모델을 적용하는 경우의 설정입니다.

- 모델에 엄격한 대기 시간이 있거나 낮은 연결성의 환경에서 실행해야 합니다.

  몰입형 증강 현실 애플리케이션을 구축하는 경우 원격 서버에 쿼리 하는 것은 실행 가능한 옵션이 아닙니다.

- 모델은 대상 기기의 메모리 및 전력 제약 조건에서 실행할 수 있을 정도로 작게 만들어야 합니다.

- 가능한 가장 높은 정확도를 얻는 작업에 중요하지 않으며, 런타임 효율성과 정확도 사이에는 항상 절충점이

  있으므로 메모리 및 전력 제약이 좋지 않은 상태의 모델을 출시할 수도 있습니다. 하지만 대형 GPU 환경에서

  실행할 수 있는 모델입니다.

- 입력 데이터는 매우 민감하므로 원격 서버에 해독할 수 없도록 해야 합니다.



스팸 탐지 모델은 채팅 앱의 일부로 최종 사용자의 스마트폰에서 실행되어야 합니다. 

메시지가 종단 간 암호화되어 원격으로 호스팅 되는 모델에서 전혀 읽을 수 없기 때문입니다.

또한, 불량 쿠키 탐지 모델에는 엄격한 대기 시간 제약이 있으며 공장에서 실행해야 합니다.

이 경우에는 전력이나 공간에 대한 제약이 없으므로 실제 GPU 환경에서 모델을 실행할 수 있습니다.



스마트폰이나 임베디드 장치에 Keras 모델을 배포하기 위해서는 TensorFlow Lite를 선택해야 합니다.

Tensor Flow는 Android 및 iOS 스마트폰은 물론, ARM64 기반의 컴퓨터, 라즈베리 파이 또는 특정 

마이크로컨트롤러에서 실행되는 효율적인 기기 내 딥 러닝 추론을 위한 프레임워크입니다. 

Keras 모델을 TensorFlow Lite 형식으로 직접 변환할 수 있는 변환기가 포함되어 있습니다.



**브라우저에서 모델 적용**

딥 러닝은 브라우저 기반 또는 데스크톱 기반 JavaScript 애플리케이션에서 자주 사용됩니다.

애플리케이션이 REST API를 통해 원격 모델을 쿼리 하는 대신 사용자 컴퓨터의 브라우저에서 모델을

직접 실행하는 주요 이점이 있을 수 있습니다.(사용 가능한 경우 GPU 리소스 활용)



브라우저 모델을 적용하는 경우의 설정입니다.

- 서버 비용을 크게 줄일 수 있는 최종 사용자에게 컴퓨팅을 오프로드 해야 합니다.

- 입력 데이터는 최종 사용자의 컴퓨터나 전화에 남아 있어야 합니다.

- 애플리케이션에는 엄격한 대기시간 제약이 있으므로 최종 사용자는 랩톱 또는 스마트폰에서 실행되는

  모델은 자체 서버의 대형 GPU에서 실행되는 모델보다 느릴 수 있지만 추가의 100ms 네트워크 통신이 없습니다.

- 모델을 다운로드하고 캐시 한 후 연결 없이 계속 작동하려면 앱이 필요합니다.



물론 모델이 사용자 랩톱이나 스마트폰의 CPU, GPU, RAM을 차지하지 않을 만큼 작은 경우에만 이 옵션을 사용해야 합니다.

또한 전체 모델이 사용자의 장치에 다운로드되기 때문에 모델에 대해 기밀로 유지할 필요가 없는지 확인해야 하며,

훈련된 딥 러닝 모델이 주어지면 훈련 데이터에 대한 일부 정보를 복구할 수 있다는 것을 알아야 합니다.

민감한 데이터에 대해 훈련된 모델을 공개하지 않는 것이 좋습니다.



JavaScript로 모델을 배포하기 위해 TensorFlow는 Keras API를 구현하는 딥 러닝용 JavaScript 라이브러리인 TensorFlow.js가 포함되어 있습니다.

뿐만 아니라 하위 수준 TensorFlow API, 저장된 Keras 모델을 TensorFlow.js로 쉽게 가져와 브라우저 기반 JavaScript 앱 또는 데스크톱 Electron 앱의 일부로 쿼리 할 수 있습니다.



**추론 모델 최적화**

추론을 위해 모델을 최적화하는 것은 가용 전력 및 메모리에 대한 엄격한 제약이 있는 환경 또는 대기 시간 요구 사항이 낮은 애플리케이션에 배포할 때 특히 중요합니다.

TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야합니다.



이를 적용할 수 있는 두 가지 인기 있는 최적화 기술이 있습니다.

1. 가중치 가지치기(Weight pruning) : 가장 중요한 매개변수만 유지하여 모델 레이어의 매개변수 수를 상당히 줄일 수 있습니다.

   성능 메트릭에서 적은 비용으로 모델의 메모리 및 컴퓨팅 공간이 줄어들게 되며 적용하려는 가지치기의 양을 

   조정하여 크기와 정확도 사이의 균형을 제어할 수 있습니다.

2. 가중치 양자화(Weight quantization) : 딥 러닝 모델은 단일 정밀도 부동 소수점(`float32`) 가중치로 학습됩니다.

   가중치를 8비트 부호 있는 정수(`int8`)로 양자화하여 4배 더 작지만 원래 모델의 정확도에 가깝게 유지되는 추론 전용 모델을 얻을 수 있습니다.



TensorFlow에는 Keras API와 긴밀하게 통합된 가중치 제거 및 양자화 툴킷이 포함되어 있습니다.



### 3.3 야생에서 모델 모니터링

모델을 배포한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 비즈니스 메트릭에 대한 영향 등을 지속적으로 모니터링해야 합니다.

- 배포 후 사용자의 참여가 증가했는지, 감소했는지 모니터링
- 생산 데이터에 대한 모델 예측의 정기적인 수동 감사를 수행
- 수동 감사가 불가능한 경우, 사용자 설문 조사와 같은 대체 평가 수단 고려



### 3.4 모델 유지 관리

영원히 지속되는 모델은 없습니다. 시간이 지남에 따라 생산 데이터의 특성이 변경되어 모델의 성능과 관련성이

점차 저하될 것입니다. 이는 개념 드리프트(Concept dript)를 통해 알 수 있습니다.



따라서, 모델이 출시되자마자 이를 대체할 차세대 훈련 모델을 준비해야 합니다.

1. 생산 데이터의 변경 사항을 검토한다.
2. 새로운 기능을 사용할 수 있는지 검토한다.
3. 레이블 세트를 확장하거나 편집해야 하는지 검토한다.
4. 지속해서 데이터를 수집하고, 주석을 다는 등 주석 파이프라인을 개선한다.
5. 특히, 데이터 샘플 수집하는 데 각별한 주의를 기울인다.

위 과정을 실행에 옮기면 성능 향상에 큰 도움이 될 것입니다.



## 요약정리

머신러닝 프로젝트를 진행할 때, 먼저 직면한 문제를 정의해야 합니다.

- 문제에 대한 맥락을 이해해야 한다.
- 제약 조건이 무엇인지 알아야 한다.
- 데이터 세트를 수집하고 주석을 달아야 한다.
- 성공을 측정하는 방법을 선택한다.



이후 문제를 이해하고 적절한 데이터 세트가 있으면 모델 구현을 합니다.

- 데이터를 준비하여 평가 프로토콜을 선택하고 유효성 감사 사용을 판단한다.
- 통계적 능력 달성 : 단순한 기준선을 능가해야 한다.
- 과대적합이 가능한 모델을 개발한다.
- 검증 데이터에 대한 성능을 기반으로 모델을 정규화하고 하이퍼파라미터를 조정한다.



마지막으로 모델이 준비되고, 테스트까지 끝마치면 배포합니다.

- 이해관계자와 적절한 기대치를 설정한다.

- 추론을 위해 최종 모델을 최적화하고 웹서버, 모바일, 브라우저, 임베디드 장치 등의 

  배포 환경을 선택하고 모델을 제공한다.

- 생산에서 모델의 성능을 모니터링하고 데이터를 계속 수집하여 차세대 모델을 개발한다.

